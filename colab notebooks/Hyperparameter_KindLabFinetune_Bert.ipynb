{"cells":[{"cell_type":"code","source":["pip install -U transformers datasets seqeval scikit-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lDuy6OxVpzgl","executionInfo":{"status":"ok","timestamp":1745853700569,"user_tz":-330,"elapsed":22944,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"a16e5dc1-9994-41ce-a984-4dae202fe44a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n","Collecting datasets\n","  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n","  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Downloading datasets-3.5.1-py3-none-any.whl (491 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=da04ebd2a5826d4b43d6707d5e70dd885cddf99f6aaa122b8f3290bee1645e4a\n","  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n","Successfully built seqeval\n","Installing collected packages: xxhash, fsspec, dill, multiprocess, seqeval, datasets\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2025.3.2\n","    Uninstalling fsspec-2025.3.2:\n","      Successfully uninstalled fsspec-2025.3.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.5.1 dill-0.3.8 fsspec-2025.3.0 multiprocess-0.70.16 seqeval-1.2.2 xxhash-3.5.0\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","%cd gdrive/MyDrive\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kpRpeyKksYcf","executionInfo":{"status":"ok","timestamp":1745853723270,"user_tz":-330,"elapsed":22699,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"38617412-10de-4842-867d-ecb34cd5962b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","/content/gdrive/MyDrive\n"]}]},{"cell_type":"code","source":["import json\n","import random\n","from datasets import Dataset, DatasetDict\n","from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, pipeline\n","from transformers import DataCollatorForTokenClassification\n","from sklearn.model_selection import train_test_split\n","from collections import defaultdict"],"metadata":{"id":"NE2fwMSxHfgh","executionInfo":{"status":"ok","timestamp":1745853757783,"user_tz":-330,"elapsed":34579,"user":{"displayName":"Samyak","userId":"04413159794314589556"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Step 1: Load discharge summaries\n","import json\n","from collections import defaultdict\n","datapath = '/content/gdrive/MyDrive/full_discharge_summaries_and_annotations/'\n","with open(datapath+\"discharge_summaries.json\", \"r\") as f:\n","    summaries = json.load(f)\n","text_by_docid = {item[\"document_id\"]: item[\"text\"] for item in summaries}\n","\n","# Step 2: Load annotations\n","with open(datapath+\"annotations.json\", \"r\") as f:\n","    annotations = json.load(f)"],"metadata":{"id":"UDXTISU2HhkM","executionInfo":{"status":"ok","timestamp":1745853758305,"user_tz":-330,"elapsed":525,"user":{"displayName":"Samyak","userId":"04413159794314589556"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Step 3: Group annotations by document_id\n","annotations_by_doc = defaultdict(list)\n","for ann in annotations:\n","    doc_id = ann[\"document_id\"]\n","    annotations_by_doc[doc_id].append({\n","        \"start\": ann[\"start\"],\n","        \"end\": ann[\"stop\"],\n","        \"label\": (ann[\"entity_type\"].replace(\"IDNUM\", \"ID\")).replace(\"PHONE\", \"CONTACT\")\n","    })\n","\n","# Step 4: Prepare examples\n","examples = []\n","for doc_id, labels in annotations_by_doc.items():\n","    if doc_id not in text_by_docid:\n","        continue\n","    text = text_by_docid[doc_id]\n","    examples.append((text, labels))\n","\n","# Step 5: Split train/test\n","train_data, test_data = train_test_split(examples, test_size=0.2, random_state=42)"],"metadata":{"id":"oa6GiDXHzEZI","executionInfo":{"status":"ok","timestamp":1745853758329,"user_tz":-330,"elapsed":16,"user":{"displayName":"Samyak","userId":"04413159794314589556"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Step 6: Load tokenizer\n","model_checkpoint = \"KindLab/bert-deid\"\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n","\n","# Step 7: Create flat label list\n","label_list = [\"O\", \"AGE\", \"CONTACT\", \"DATE\", \"ID\", \"LOCATION\", \"NAME\", \"PROFESSION\"]\n","label2id = {label: i for i, label in enumerate(label_list)}\n","id2label = {i: label for label, i in label2id.items()}"],"metadata":{"id":"_VU6b2DY7atf","executionInfo":{"status":"ok","timestamp":1745853761103,"user_tz":-330,"elapsed":2766,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"colab":{"base_uri":"https://localhost:8080/","height":269,"referenced_widgets":["6b29739ab2f6449481164397c276a13c","01a1e2882b9c4e509bf2ebd7319561d5","24a8cf53d67648a79639b87bd08f57aa","35340730c7c341858b6dec4fb787c18b","382dbf1cb8dc4c868c5f2e0036a65ef1","8f0f66de5a2a40368dfbbe865b7ab194","1031406125974255bfab9510b0207082","6cd6cba0f6ad4d739bb3834f30ae3ec7","67bb766165d64af4b8efae4a5dbe4c04","e4d5b04d5ec642768c791ede5530c8eb","bbe4ac5298c74d6ea214f5b19c46b2c3","2845e1c473fb4b0d8d481864fba771be","b74cb9d12ca24301a0dd90e2e78b3046","29f69122b88042d1b88bef9c8a0e2ae1","39149bef0b354567acd6b112a969ec59","a879a0cfd80c4ca8bf3725d1f67e5a7f","bdc6373a68f346b0aaf0259ac11a6a1f","3e73e189ba19479ca43c817b89acc950","7eba654b3e5447eead64b73c356f29d7","4580cf3222604aa4bf3b2176bfc4bc17","999a7a11ec0f4efb8d5a2387a0df7acf","01c82e6413cc41cfbcecb1051de6bc24","a1ed41c926d84fc1bc88c2fa4c2f1311","187c327821584aea9c854839f7e3e569","855fcca881de4f41abb05c316a8d2835","b7bcc9c1d4a847ccbd6a55b5dcc5fc1e","525b484a118643b8ab0be661d0ea9a58","85167696f0c342c49cff8c1160837271","ab9bf9136fc74f5f89341d6ba7d36f0e","a152f5a0e84841e9ba27065d4f8a002e","83f598c8e8f04fef88b11bffa5b71777","93076cb254a04d27bf0d95408932d212","9f2b3eebb79740199a84c31aa3af834b","5aa13dd2d89a4b33a496a900fcb80a13","87ef38f2d6bf4aefbc289f11da574fd7","04401a97ac6a442398e4e321a4ee51aa","fdd3468b02424204856dd8bae013fedc","6fe6031e1d434ac5af150cbee1ba06df","801cdb9caf6e41958b55593331cfcba5","e2962c3f72584e18aa56c2ac74da4728","3286763181354e689251d1c335b8e861","6c8460b230e24b52b085d6ad6e9205cf","b6cd3f0d116f44188106b0486d334266","d4ec69e8da494ba0a2619a7c6cd4b7de"]},"outputId":"f76fb64e-8e95-4131-9830-e36f8ec04d88"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b29739ab2f6449481164397c276a13c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2845e1c473fb4b0d8d481864fba771be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1ed41c926d84fc1bc88c2fa4c2f1311"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5aa13dd2d89a4b33a496a900fcb80a13"}},"metadata":{}}]},{"cell_type":"code","source":["# Step 8: Align labels with tokens\n","def align_labels_with_tokens(text, labels, tokenizer):\n","    tokenized_inputs = tokenizer(\n","        text,\n","        truncation=True,\n","        padding=\"max_length\",\n","        max_length=512,\n","        return_offsets_mapping=True\n","    )\n","    labels_aligned = [\"O\"] * len(tokenized_inputs[\"input_ids\"])\n","    offset_mapping = tokenized_inputs.pop(\"offset_mapping\")\n","\n","    for entity in labels:\n","        start, end, label = entity[\"start\"], entity[\"end\"], entity[\"label\"]\n","        for i, (offset_start, offset_end) in enumerate(offset_mapping):\n","            if offset_start >= end:\n","                break\n","            if offset_end > start and offset_start < end:\n","                labels_aligned[i] = label.replace(\" \", \"_\")\n","\n","    return {\n","        \"input_ids\": tokenized_inputs[\"input_ids\"],\n","        \"attention_mask\": tokenized_inputs[\"attention_mask\"],\n","        \"labels\": [label2id.get(lbl, 0) for lbl in labels_aligned]\n","    }"],"metadata":{"id":"hg8lAksw7awr","executionInfo":{"status":"ok","timestamp":1745853761108,"user_tz":-330,"elapsed":4,"user":{"displayName":"Samyak","userId":"04413159794314589556"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Step 9: Tokenize dataset\n","train_dataset = Dataset.from_list([align_labels_with_tokens(x[0], x[1], tokenizer) for x in train_data])\n","test_dataset = Dataset.from_list([align_labels_with_tokens(x[0], x[1], tokenizer) for x in test_data])\n","\n","dataset = DatasetDict({\n","    \"train\": train_dataset,\n","    \"test\": test_dataset\n","})\n","\n","# Step 10: Load model\n","model = AutoModelForTokenClassification.from_pretrained(\n","    model_checkpoint,\n","    num_labels=len(label_list),\n","    id2label=id2label,\n","    label2id=label2id\n",")\n"],"metadata":{"id":"e65j64-K7a0S","executionInfo":{"status":"ok","timestamp":1745853767002,"user_tz":-330,"elapsed":5893,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["9a111d18931a4f069f363928f53d467b","06903ebd44844c2a9aa3ec61c155d9da","2063971605d54811ab616f7f09ee4c52","0fd01f62fe53461dafa0a3d5ac04f275","20a421f2869c47c8a76d1ade7e883a91","521ef503342a4075accbcb4e5b5c3165","6b6338805f994c86a64297471c0d69fe","ff01a368832b417ab6f30b31d22a2c75","c33adb58eeb944018803a0223957681a","34d44ccf64654bde98fb8611868cc6ee","cd28712f0ff14bc49023b976c01f8e61","0ecf2ca697294e1fa07d8d08fab36b64","13a484d3f6f1447bbc78495480665d36","a93e7affa86c4bde8a24f1df55668bab","e5768460ef204b5eb474617dd219846c","251316a251bf4b1687f3e8b1d7f9229a","0328720657804805976f66a7f3cd4420","a7420cf3b972433cb51aa8389c23bc87","d957d5720d8a4901962f199ceb31a990","3e090726a19744bfbe2d152a072fc0fa","a0a2b256cb5344388e0f8bd2bad5392b","6c6f24e03257444e959a7e4c11db4616"]},"outputId":"c9c25544-9e51-4b9c-dcbd-be3aaff3fc60"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/983 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a111d18931a4f069f363928f53d467b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/431M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ecf2ca697294e1fa07d8d08fab36b64"}},"metadata":{}}]},{"cell_type":"code","source":["!pip install evaluate\n","from transformers import TrainerCallback\n","from evaluate import load\n","\n","# Load metrics\n","seqeval = load(\"seqeval\")\n","\n","# Custom compute_metrics function\n","def compute_metrics(predictions):\n","    preds, labels = predictions\n","    preds = preds.argmax(-1)\n","\n","    true_predictions = [\n","        [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(preds, labels)\n","    ]\n","    true_labels = [\n","        [id2label[l] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(preds, labels)\n","    ]\n","\n","    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n","    return {\n","        \"precision\": results[\"overall_precision\"],\n","        \"recall\": results[\"overall_recall\"],\n","        \"f1\": results[\"overall_f1\"],\n","        \"accuracy\": results[\"overall_accuracy\"],\n","    }"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":723,"referenced_widgets":["f9df226eceba40d0aacefe835af3d099","5672f34d42fe4176ac13aaa9dcdfddf7","13383afc708b4ff5bbad4494dabcc66f","1e0f5fd895034089b4a56f66d482ae11","ee3ae39998c64beb847d70f8736d808e","84b2ec9134c04a30a8d26aea9ea77e2f","d89f88f9bbf44e87b355fc9f00e6403d","554b2c50f3b64fb8894d0a6913925cd0","624eed160b8a43669602a3e3efaa8130","7d4e721174c3437d96286a902e0f6bb2","0bfe33657ead4d08a91a790f4442a289","27c0524723164152863a33ad29a11c83","1a634306035b44c799e22b46e6c35cbb","e831bf324de84048baea27b7e5840e88","d7d2f4cc7cd249719aa8547737a6c0f7","18d3335736a7403386f7bed85e73e804","4db9b502ca1a43d0b77953b567da43ea","cdd24c397747473193f48d3f749230af","f7bd2ab6525a4908ab68087bc8b61a95","429fd8e4df38489896ea60332aa27b84","ccb9d8150a3a4e6a86fceb19940f5d1b","7b87a9800fe84cabaf3a652a1c7d1832"]},"id":"OLfU-WHHrnma","executionInfo":{"status":"ok","timestamp":1745853772425,"user_tz":-330,"elapsed":5424,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"ed5f2ae2-a3fc-4789-a9d7-f024d2bd4089"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/431M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9df226eceba40d0aacefe835af3d099"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting evaluate\n","  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.30.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.15)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n","Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m103.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: evaluate\n","Successfully installed evaluate-0.4.3\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27c0524723164152863a33ad29a11c83"}},"metadata":{}}]},{"cell_type":"markdown","source":["# Batch size 8, Epochs 3, Learning rate = 2e-5"],"metadata":{"id":"0lm9Gecibif2"}},{"cell_type":"code","source":["import time\n","\n","# Start timer\n","start_time = time.time()\n","\n","# Step 11: Setup Data Collator\n","data_collator = DataCollatorForTokenClassification(\n","    tokenizer,\n","    padding=True,\n","    max_length=512,\n","    return_tensors=\"pt\"\n",")\n","\n","# Step 12: Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./kindlab_bert_deid_finetuned\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=3,\n","    learning_rate=2e-5,\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    save_steps=200,\n","    save_total_limit=2,\n","    remove_unused_columns=False\n",")\n","\n","# Step 13: Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")\n","\n","# Step 14: Train\n","trainer.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"b-SHJu3LzEt3","executionInfo":{"status":"ok","timestamp":1745761271312,"user_tz":-330,"elapsed":282952,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"913bef15-4457-42c1-cb1f-107435257ec0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msamyakjainuiuc\u001b[0m (\u001b[33msamyakjainuiuc-university-of-illionis-urbana-champaign\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.9"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/gdrive/MyDrive/wandb/run-20250427_133654-rzftxj6d</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/samyakjainuiuc-university-of-illionis-urbana-champaign/huggingface/runs/rzftxj6d' target=\"_blank\">./kindlab_bert_deid_finetuned</a></strong> to <a href='https://wandb.ai/samyakjainuiuc-university-of-illionis-urbana-champaign/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/samyakjainuiuc-university-of-illionis-urbana-champaign/huggingface' target=\"_blank\">https://wandb.ai/samyakjainuiuc-university-of-illionis-urbana-champaign/huggingface</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/samyakjainuiuc-university-of-illionis-urbana-champaign/huggingface/runs/rzftxj6d' target=\"_blank\">https://wandb.ai/samyakjainuiuc-university-of-illionis-urbana-champaign/huggingface/runs/rzftxj6d</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 04:07, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.136800</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.019500</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.007400</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.004600</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.002300</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.001900</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.001300</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.001400</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.001300</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.001200</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.000600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=300, training_loss=0.006454857971984893, metrics={'train_runtime': 273.6406, 'train_samples_per_second': 8.771, 'train_steps_per_second': 1.096, 'total_flos': 627146234265600.0, 'train_loss': 0.006454857971984893, 'epoch': 3.0})"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from transformers import DataCollatorForTokenClassification\n","from seqeval.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n","\n","small_test_dataset = dataset[\"test\"].select(range(100))\n","# Set up DataCollator\n","data_collator = DataCollatorForTokenClassification(tokenizer, padding=True, return_tensors=\"pt\")\n","test_dataloader = DataLoader(small_test_dataset, batch_size=8, collate_fn=data_collator)\n","\n","# Move model to device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.eval()\n","\n","all_preds = []\n","all_labels = []\n","\n","# Evaluate\n","with torch.no_grad():\n","    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        predictions = logits.argmax(dim=-1)\n","\n","        all_preds.append(predictions.cpu().numpy())\n","        all_labels.append(labels.cpu().numpy())\n","\n","# Stack all batches\n","all_preds = np.concatenate(all_preds, axis=0)\n","all_labels = np.concatenate(all_labels, axis=0)\n","\n","# Decode predictions\n","true_predictions = []\n","true_labels = []\n","\n","for prediction, label in zip(all_preds, all_labels):\n","    temp_pred = []\n","    temp_label = []\n","    for p, l in zip(prediction, label):\n","        if l == -100:\n","            continue\n","        temp_pred.append(id2label[p])\n","        temp_label.append(id2label[l])\n","    true_predictions.append(temp_pred)\n","    true_labels.append(temp_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O1SBYuk63DL6","executionInfo":{"status":"ok","timestamp":1745761274408,"user_tz":-330,"elapsed":3097,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"80fc340f-3ead-4aa6-ce4e-9e779e35b25a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 13/13 [00:03<00:00,  4.08it/s]\n"]}]},{"cell_type":"code","source":["print(\"Metrics computed using seqeval:\")\n","print(\"Accuracy:\", accuracy_score(true_labels, true_predictions))\n","print(\"Precision:\", precision_score(true_labels, true_predictions))\n","print(\"Recall:\", recall_score(true_labels, true_predictions))\n","print(\"F1:\", f1_score(true_labels, true_predictions))\n","print(\"\\nDetailed Classification Report:\\n\")\n","print(classification_report(true_labels, true_predictions))\n","\n","# End timer\n","end_time = time.time()\n","\n","# Compute elapsed time\n","elapsed_time = end_time - start_time\n","\n","print(f\"Time taken: {elapsed_time:.2f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QCO2rgkbAoSy","executionInfo":{"status":"ok","timestamp":1745761276842,"user_tz":-330,"elapsed":2194,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"3b03f5a7-8442-4198-f0f9-541f932b369a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NAME seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ID seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DATE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AGE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LOCATION seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONTACT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"]},{"output_type":"stream","name":"stdout","text":["Metrics computed using seqeval:\n","Accuracy: 0.99970703125\n","Precision: 0.9853768278965129\n","Recall: 0.9977220956719818\n","F1: 0.9915110356536503\n","\n","Detailed Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","         AME       1.00      1.00      1.00       200\n","         ATE       1.00      1.00      1.00       300\n","           D       1.00      1.00      1.00       100\n","          GE       0.85      0.97      0.91        78\n","     OCATION       1.00      1.00      1.00       100\n","      ONTACT       1.00      1.00      1.00       100\n","\n","   micro avg       0.99      1.00      0.99       878\n","   macro avg       0.98      1.00      0.99       878\n","weighted avg       0.99      1.00      0.99       878\n","\n","Time taken: 288.30 seconds\n"]}]},{"cell_type":"markdown","source":["# Batch size 16, Epochs 3, Learning rate = 2e-5"],"metadata":{"id":"AgjE4tuHcfoM"}},{"cell_type":"code","source":["# Step 10: Load model\n","model = AutoModelForTokenClassification.from_pretrained(\n","    model_checkpoint,\n","    num_labels=len(label_list),\n","    id2label=id2label,\n","    label2id=label2id\n",")"],"metadata":{"id":"MHpmkLJjfb84"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","# Start timer\n","start_time = time.time()\n","\n","# Step 11: Setup Data Collator\n","data_collator = DataCollatorForTokenClassification(\n","    tokenizer,\n","    padding=True,\n","    max_length=512,\n","    return_tensors=\"pt\"\n",")\n","\n","# Step 12: Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./kindlab_bert_deid_finetuned\",\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=3,\n","    learning_rate=2e-5,\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    save_steps=200,\n","    save_total_limit=2,\n","    remove_unused_columns=False\n",")\n","\n","# Step 13: Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")\n","\n","# Step 14: Train\n","trainer.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":635},"executionInfo":{"status":"ok","timestamp":1745761706890,"user_tz":-330,"elapsed":245457,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"856b9dbb-009e-4dcb-cf81-aca627562b37","id":"__GqBU1XcfoM"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [150/150 04:03, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.159000</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.024300</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.006800</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.002800</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.003100</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.001700</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.001500</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.001700</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.001500</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.001000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=150, training_loss=0.013908469875653584, metrics={'train_runtime': 244.9448, 'train_samples_per_second': 9.798, 'train_steps_per_second': 0.612, 'total_flos': 627146234265600.0, 'train_loss': 0.013908469875653584, 'epoch': 3.0})"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from transformers import DataCollatorForTokenClassification\n","from seqeval.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n","\n","small_test_dataset = dataset[\"test\"].select(range(100))\n","# Set up DataCollator\n","data_collator = DataCollatorForTokenClassification(tokenizer, padding=True, return_tensors=\"pt\")\n","test_dataloader = DataLoader(small_test_dataset, batch_size=16, collate_fn=data_collator)\n","\n","# Move model to device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.eval()\n","\n","all_preds = []\n","all_labels = []\n","\n","# Evaluate\n","with torch.no_grad():\n","    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        predictions = logits.argmax(dim=-1)\n","\n","        all_preds.append(predictions.cpu().numpy())\n","        all_labels.append(labels.cpu().numpy())\n","\n","# Stack all batches\n","all_preds = np.concatenate(all_preds, axis=0)\n","all_labels = np.concatenate(all_labels, axis=0)\n","\n","# Decode predictions\n","true_predictions = []\n","true_labels = []\n","\n","for prediction, label in zip(all_preds, all_labels):\n","    temp_pred = []\n","    temp_label = []\n","    for p, l in zip(prediction, label):\n","        if l == -100:\n","            continue\n","        temp_pred.append(id2label[p])\n","        temp_label.append(id2label[l])\n","    true_predictions.append(temp_pred)\n","    true_labels.append(temp_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745761709921,"user_tz":-330,"elapsed":3029,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"db1491f6-5af1-4bd8-b766-f8f6417d7d81","id":"0YIFfdGLcfoN"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 7/7 [00:02<00:00,  2.35it/s]\n"]}]},{"cell_type":"code","source":["print(\"Metrics computed using seqeval:\")\n","print(\"Accuracy:\", accuracy_score(true_labels, true_predictions))\n","print(\"Precision:\", precision_score(true_labels, true_predictions))\n","print(\"Recall:\", recall_score(true_labels, true_predictions))\n","print(\"F1:\", f1_score(true_labels, true_predictions))\n","print(\"\\nDetailed Classification Report:\\n\")\n","print(classification_report(true_labels, true_predictions))\n","\n","# End timer\n","end_time = time.time()\n","\n","# Compute elapsed time\n","elapsed_time = end_time - start_time\n","\n","print(f\"Time taken: {elapsed_time:.2f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745761711139,"user_tz":-330,"elapsed":1217,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"daa84638-5d7a-4566-d8fb-03f24a550d0d","id":"XTqOa6hscfoO"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NAME seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ID seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DATE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AGE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LOCATION seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONTACT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"]},{"output_type":"stream","name":"stdout","text":["Metrics computed using seqeval:\n","Accuracy: 0.9996484375\n","Precision: 0.9809630459126539\n","Recall: 0.9977220956719818\n","F1: 0.9892715979672502\n","\n","Detailed Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","         AME       0.99      0.99      0.99       200\n","         ATE       1.00      1.00      1.00       300\n","           D       1.00      1.00      1.00       100\n","          GE       0.83      0.99      0.90        78\n","     OCATION       1.00      1.00      1.00       100\n","      ONTACT       1.00      1.00      1.00       100\n","\n","   micro avg       0.98      1.00      0.99       878\n","   macro avg       0.97      1.00      0.98       878\n","weighted avg       0.98      1.00      0.99       878\n","\n","Time taken: 249.68 seconds\n"]}]},{"cell_type":"markdown","source":["# Batch size 32, Epochs 3, Learning rate = 2e-5"],"metadata":{"id":"BkdD3Jl1csyM"}},{"cell_type":"code","source":["# Step 10: Load model\n","model = AutoModelForTokenClassification.from_pretrained(\n","    model_checkpoint,\n","    num_labels=len(label_list),\n","    id2label=id2label,\n","    label2id=label2id\n",")"],"metadata":{"id":"SjOQu7U_ffwv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","# Start timer\n","start_time = time.time()\n","\n","# Step 11: Setup Data Collator\n","data_collator = DataCollatorForTokenClassification(\n","    tokenizer,\n","    padding=True,\n","    max_length=512,\n","    return_tensors=\"pt\"\n",")\n","\n","# Step 12: Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./kindlab_bert_deid_finetuned\",\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    num_train_epochs=3,\n","    learning_rate=2e-5,\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    save_steps=200,\n","    save_total_limit=2,\n","    remove_unused_columns=False\n",")\n","\n","# Step 13: Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")\n","\n","# Step 14: Train\n","trainer.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"executionInfo":{"status":"ok","timestamp":1745761953625,"user_tz":-330,"elapsed":241578,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"7d4d53f2-aeb4-4a0f-fb1b-a74f24ee1bcb","id":"CpO8NxSucsyM"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [75/75 03:57, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.147000</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.018400</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.007200</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.003800</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.002700</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.002000</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.002000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=75, training_loss=0.02460856596628825, metrics={'train_runtime': 240.955, 'train_samples_per_second': 9.96, 'train_steps_per_second': 0.311, 'total_flos': 627146234265600.0, 'train_loss': 0.02460856596628825, 'epoch': 3.0})"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from transformers import DataCollatorForTokenClassification\n","from seqeval.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n","\n","small_test_dataset = dataset[\"test\"].select(range(100))\n","# Set up DataCollator\n","data_collator = DataCollatorForTokenClassification(tokenizer, padding=True, return_tensors=\"pt\")\n","test_dataloader = DataLoader(small_test_dataset, batch_size=32, collate_fn=data_collator)\n","\n","# Move model to device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.eval()\n","\n","all_preds = []\n","all_labels = []\n","\n","# Evaluate\n","with torch.no_grad():\n","    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        predictions = logits.argmax(dim=-1)\n","\n","        all_preds.append(predictions.cpu().numpy())\n","        all_labels.append(labels.cpu().numpy())\n","\n","# Stack all batches\n","all_preds = np.concatenate(all_preds, axis=0)\n","all_labels = np.concatenate(all_labels, axis=0)\n","\n","# Decode predictions\n","true_predictions = []\n","true_labels = []\n","\n","for prediction, label in zip(all_preds, all_labels):\n","    temp_pred = []\n","    temp_label = []\n","    for p, l in zip(prediction, label):\n","        if l == -100:\n","            continue\n","        temp_pred.append(id2label[p])\n","        temp_label.append(id2label[l])\n","    true_predictions.append(temp_pred)\n","    true_labels.append(temp_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745761956635,"user_tz":-330,"elapsed":3009,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"ca486fbf-ae1e-4217-8d0b-9d4873bc9e04","id":"1nIsgUMucsyN"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 4/4 [00:02<00:00,  1.35it/s]\n"]}]},{"cell_type":"code","source":["print(\"Metrics computed using seqeval:\")\n","print(\"Accuracy:\", accuracy_score(true_labels, true_predictions))\n","print(\"Precision:\", precision_score(true_labels, true_predictions))\n","print(\"Recall:\", recall_score(true_labels, true_predictions))\n","print(\"F1:\", f1_score(true_labels, true_predictions))\n","print(\"\\nDetailed Classification Report:\\n\")\n","print(classification_report(true_labels, true_predictions))\n","\n","# End timer\n","end_time = time.time()\n","\n","# Compute elapsed time\n","elapsed_time = end_time - start_time\n","\n","print(f\"Time taken: {elapsed_time:.2f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745761957839,"user_tz":-330,"elapsed":1202,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"65d46f34-53ad-4b92-dfe3-ec538728da40","id":"irAwWpqTcsyO"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NAME seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ID seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DATE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AGE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LOCATION seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONTACT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"]},{"output_type":"stream","name":"stdout","text":["Metrics computed using seqeval:\n","Accuracy: 0.9994921875\n","Precision: 0.9721603563474388\n","Recall: 0.9943052391799544\n","F1: 0.9831081081081081\n","\n","Detailed Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","         AME       0.97      0.97      0.97       200\n","         ATE       1.00      1.00      1.00       300\n","           D       1.00      1.00      1.00       100\n","          GE       0.80      1.00      0.89        78\n","     OCATION       1.00      1.00      1.00       100\n","      ONTACT       1.00      1.00      1.00       100\n","\n","   micro avg       0.97      0.99      0.98       878\n","   macro avg       0.96      1.00      0.98       878\n","weighted avg       0.98      0.99      0.98       878\n","\n","Time taken: 245.63 seconds\n"]}]},{"cell_type":"markdown","source":["# Batch size 16, Epochs 5, Learning rate = 2e-5"],"metadata":{"id":"GokDwUUyctx4"}},{"cell_type":"code","source":["# Step 10: Load model\n","model = AutoModelForTokenClassification.from_pretrained(\n","    model_checkpoint,\n","    num_labels=len(label_list),\n","    id2label=id2label,\n","    label2id=label2id\n",")"],"metadata":{"id":"2pPwn8kjfi9q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","# Start timer\n","start_time = time.time()\n","\n","# Step 11: Setup Data Collator\n","data_collator = DataCollatorForTokenClassification(\n","    tokenizer,\n","    padding=True,\n","    max_length=512,\n","    return_tensors=\"pt\"\n",")\n","\n","# Step 12: Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./kindlab_bert_deid_finetuned\",\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=5,\n","    learning_rate=2e-5,\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    save_steps=200,\n","    save_total_limit=2,\n","    remove_unused_columns=False\n",")\n","\n","# Step 13: Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")\n","\n","# Step 14: Train\n","trainer.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":983},"executionInfo":{"status":"ok","timestamp":1745762429984,"user_tz":-330,"elapsed":396215,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"20ff7a6d-e77b-4836-bfe4-1a5c4f31ac31","id":"exuk_5kZctx4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [250/250 06:34, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.158600</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.023800</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.006500</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.002700</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.002900</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.001600</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.001400</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.001500</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.001200</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.000700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=250, training_loss=0.008512625098228454, metrics={'train_runtime': 395.5678, 'train_samples_per_second': 10.112, 'train_steps_per_second': 0.632, 'total_flos': 1045243723776000.0, 'train_loss': 0.008512625098228454, 'epoch': 5.0})"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from transformers import DataCollatorForTokenClassification\n","from seqeval.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n","\n","small_test_dataset = dataset[\"test\"].select(range(100))\n","# Set up DataCollator\n","data_collator = DataCollatorForTokenClassification(tokenizer, padding=True, return_tensors=\"pt\")\n","test_dataloader = DataLoader(small_test_dataset, batch_size=16, collate_fn=data_collator)\n","\n","# Move model to device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.eval()\n","\n","all_preds = []\n","all_labels = []\n","\n","# Evaluate\n","with torch.no_grad():\n","    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        predictions = logits.argmax(dim=-1)\n","\n","        all_preds.append(predictions.cpu().numpy())\n","        all_labels.append(labels.cpu().numpy())\n","\n","# Stack all batches\n","all_preds = np.concatenate(all_preds, axis=0)\n","all_labels = np.concatenate(all_labels, axis=0)\n","\n","# Decode predictions\n","true_predictions = []\n","true_labels = []\n","\n","for prediction, label in zip(all_preds, all_labels):\n","    temp_pred = []\n","    temp_label = []\n","    for p, l in zip(prediction, label):\n","        if l == -100:\n","            continue\n","        temp_pred.append(id2label[p])\n","        temp_label.append(id2label[l])\n","    true_predictions.append(temp_pred)\n","    true_labels.append(temp_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745762433323,"user_tz":-330,"elapsed":3324,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"bd8477bf-812d-47a8-aed7-3acc7aac723b","id":"JAZj5Z8Fctx5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 7/7 [00:02<00:00,  2.34it/s]\n"]}]},{"cell_type":"code","source":["print(\"Metrics computed using seqeval:\")\n","print(\"Accuracy:\", accuracy_score(true_labels, true_predictions))\n","print(\"Precision:\", precision_score(true_labels, true_predictions))\n","print(\"Recall:\", recall_score(true_labels, true_predictions))\n","print(\"F1:\", f1_score(true_labels, true_predictions))\n","print(\"\\nDetailed Classification Report:\\n\")\n","print(classification_report(true_labels, true_predictions))\n","\n","# End timer\n","end_time = time.time()\n","\n","# Compute elapsed time\n","elapsed_time = end_time - start_time\n","\n","print(f\"Time taken: {elapsed_time:.2f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745762433824,"user_tz":-330,"elapsed":500,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"81a6b94f-90eb-48ee-8c18-6ecb91b0ee58","id":"6-kC5lkNctx5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NAME seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ID seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DATE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AGE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LOCATION seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONTACT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"]},{"output_type":"stream","name":"stdout","text":["Metrics computed using seqeval:\n","Accuracy: 0.9996875\n","Precision: 0.9853603603603603\n","Recall: 0.9965831435079726\n","F1: 0.9909399773499433\n","\n","Detailed Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","         AME       1.00      1.00      1.00       200\n","         ATE       1.00      1.00      1.00       300\n","           D       1.00      1.00      1.00       100\n","          GE       0.85      0.96      0.90        78\n","     OCATION       1.00      1.00      1.00       100\n","      ONTACT       1.00      1.00      1.00       100\n","\n","   micro avg       0.99      1.00      0.99       878\n","   macro avg       0.98      0.99      0.98       878\n","weighted avg       0.99      1.00      0.99       878\n","\n","Time taken: 400.13 seconds\n"]}]},{"cell_type":"markdown","source":["# Batch size 16, Epochs 4, Learning rate = 2e-5"],"metadata":{"id":"re7F2BGtcuqu"}},{"cell_type":"code","source":["# Step 10: Load model\n","model = AutoModelForTokenClassification.from_pretrained(\n","    model_checkpoint,\n","    num_labels=len(label_list),\n","    id2label=id2label,\n","    label2id=label2id\n",")"],"metadata":{"id":"8hITfJDqfsT-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","# Start timer\n","start_time = time.time()\n","\n","# Step 11: Setup Data Collator\n","data_collator = DataCollatorForTokenClassification(\n","    tokenizer,\n","    padding=True,\n","    max_length=512,\n","    return_tensors=\"pt\"\n",")\n","\n","# Step 12: Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./kindlab_bert_deid_finetuned\",\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=4,\n","    learning_rate=2e-5,\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    save_steps=200,\n","    save_total_limit=2,\n","    remove_unused_columns=False\n",")\n","\n","# Step 13: Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")\n","\n","# Step 14: Train\n","trainer.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":792},"executionInfo":{"status":"ok","timestamp":1745762825307,"user_tz":-330,"elapsed":315296,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"22b28e79-a3c3-4d54-d015-1944ba19c741","id":"_VeRzAsmcuqv"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 05:12, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.158800</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.024000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.006600</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.002700</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.003000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.001700</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.001400</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.001600</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.001300</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.000700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=200, training_loss=0.010516795320436359, metrics={'train_runtime': 314.2294, 'train_samples_per_second': 10.184, 'train_steps_per_second': 0.636, 'total_flos': 836194979020800.0, 'train_loss': 0.010516795320436359, 'epoch': 4.0})"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from transformers import DataCollatorForTokenClassification\n","from seqeval.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n","\n","small_test_dataset = dataset[\"test\"].select(range(100))\n","# Set up DataCollator\n","data_collator = DataCollatorForTokenClassification(tokenizer, padding=True, return_tensors=\"pt\")\n","test_dataloader = DataLoader(small_test_dataset, batch_size=16, collate_fn=data_collator)\n","\n","# Move model to device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.eval()\n","\n","all_preds = []\n","all_labels = []\n","\n","# Evaluate\n","with torch.no_grad():\n","    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        predictions = logits.argmax(dim=-1)\n","\n","        all_preds.append(predictions.cpu().numpy())\n","        all_labels.append(labels.cpu().numpy())\n","\n","# Stack all batches\n","all_preds = np.concatenate(all_preds, axis=0)\n","all_labels = np.concatenate(all_labels, axis=0)\n","\n","# Decode predictions\n","true_predictions = []\n","true_labels = []\n","\n","for prediction, label in zip(all_preds, all_labels):\n","    temp_pred = []\n","    temp_label = []\n","    for p, l in zip(prediction, label):\n","        if l == -100:\n","            continue\n","        temp_pred.append(id2label[p])\n","        temp_label.append(id2label[l])\n","    true_predictions.append(temp_pred)\n","    true_labels.append(temp_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745762828409,"user_tz":-330,"elapsed":3101,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"9b223133-10ec-41af-b89a-f187c01249ef","id":"KnYhK3Xhcuqw"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 7/7 [00:03<00:00,  2.31it/s]\n"]}]},{"cell_type":"code","source":["print(\"Metrics computed using seqeval:\")\n","print(\"Accuracy:\", accuracy_score(true_labels, true_predictions))\n","print(\"Precision:\", precision_score(true_labels, true_predictions))\n","print(\"Recall:\", recall_score(true_labels, true_predictions))\n","print(\"F1:\", f1_score(true_labels, true_predictions))\n","print(\"\\nDetailed Classification Report:\\n\")\n","print(classification_report(true_labels, true_predictions))\n","\n","# End timer\n","end_time = time.time()\n","\n","# Compute elapsed time\n","elapsed_time = end_time - start_time\n","\n","print(f\"Time taken: {elapsed_time:.2f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745762828998,"user_tz":-330,"elapsed":587,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"1bee954c-c25c-4946-9a6a-0150f21c4575","id":"IVWiGLKHcuqw"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NAME seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ID seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DATE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AGE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LOCATION seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONTACT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"]},{"output_type":"stream","name":"stdout","text":["Metrics computed using seqeval:\n","Accuracy: 0.99966796875\n","Precision: 0.9820828667413214\n","Recall: 0.9988610478359908\n","F1: 0.9904009034443816\n","\n","Detailed Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","         AME       1.00      1.00      1.00       200\n","         ATE       1.00      1.00      1.00       300\n","           D       1.00      1.00      1.00       100\n","          GE       0.83      0.99      0.90        78\n","     OCATION       1.00      1.00      1.00       100\n","      ONTACT       1.00      1.00      1.00       100\n","\n","   micro avg       0.98      1.00      0.99       878\n","   macro avg       0.97      1.00      0.98       878\n","weighted avg       0.98      1.00      0.99       878\n","\n","Time taken: 319.00 seconds\n"]}]},{"cell_type":"markdown","source":["# Batch size 8, Epochs 5, Learning rate = 2e-5"],"metadata":{"id":"ififpv3NcvhX"}},{"cell_type":"code","source":["# Step 10: Load model\n","model = AutoModelForTokenClassification.from_pretrained(\n","    model_checkpoint,\n","    num_labels=len(label_list),\n","    id2label=id2label,\n","    label2id=label2id\n",")"],"metadata":{"id":"TsITSzmJol8B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","# Start timer\n","start_time = time.time()\n","\n","# Step 11: Setup Data Collator\n","data_collator = DataCollatorForTokenClassification(\n","    tokenizer,\n","    padding=True,\n","    max_length=512,\n","    return_tensors=\"pt\"\n",")\n","\n","# Step 12: Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./kindlab_bert_deid_finetuned\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=5,\n","    learning_rate=2e-5,\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    save_steps=200,\n","    save_total_limit=2,\n","    remove_unused_columns=False\n",")\n","\n","# Step 13: Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")\n","\n","# Step 14: Train\n","trainer.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1745764260295,"user_tz":-330,"elapsed":400312,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"cc761d84-83b0-4440-f4ef-386c05b69348","id":"DjZIL7oKcvhY"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [500/500 06:38, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.136600</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.019300</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.007300</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.004500</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.002200</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.001800</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.001200</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.001300</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.001200</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.000300</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.000700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=500, training_loss=0.004088789828121662, metrics={'train_runtime': 399.4973, 'train_samples_per_second': 10.013, 'train_steps_per_second': 1.252, 'total_flos': 1045243723776000.0, 'train_loss': 0.004088789828121662, 'epoch': 5.0})"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from transformers import DataCollatorForTokenClassification\n","from seqeval.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n","\n","small_test_dataset = dataset[\"test\"].select(range(100))\n","# Set up DataCollator\n","data_collator = DataCollatorForTokenClassification(tokenizer, padding=True, return_tensors=\"pt\")\n","test_dataloader = DataLoader(small_test_dataset, batch_size=8, collate_fn=data_collator)\n","\n","# Move model to device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.eval()\n","\n","all_preds = []\n","all_labels = []\n","\n","# Evaluate\n","with torch.no_grad():\n","    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        predictions = logits.argmax(dim=-1)\n","\n","        all_preds.append(predictions.cpu().numpy())\n","        all_labels.append(labels.cpu().numpy())\n","\n","# Stack all batches\n","all_preds = np.concatenate(all_preds, axis=0)\n","all_labels = np.concatenate(all_labels, axis=0)\n","\n","# Decode predictions\n","true_predictions = []\n","true_labels = []\n","\n","for prediction, label in zip(all_preds, all_labels):\n","    temp_pred = []\n","    temp_label = []\n","    for p, l in zip(prediction, label):\n","        if l == -100:\n","            continue\n","        temp_pred.append(id2label[p])\n","        temp_label.append(id2label[l])\n","    true_predictions.append(temp_pred)\n","    true_labels.append(temp_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745764263304,"user_tz":-330,"elapsed":3013,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"80cc574e-1792-4f72-8c2e-3b923174da6c","id":"qwJYmkK4cvhY"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 13/13 [00:02<00:00,  4.44it/s]\n"]}]},{"cell_type":"code","source":["print(\"Metrics computed using seqeval:\")\n","print(\"Accuracy:\", accuracy_score(true_labels, true_predictions))\n","print(\"Precision:\", precision_score(true_labels, true_predictions))\n","print(\"Recall:\", recall_score(true_labels, true_predictions))\n","print(\"F1:\", f1_score(true_labels, true_predictions))\n","print(\"\\nDetailed Classification Report:\\n\")\n","print(classification_report(true_labels, true_predictions))\n","\n","# End timer\n","end_time = time.time()\n","\n","# Compute elapsed time\n","elapsed_time = end_time - start_time\n","\n","print(f\"Time taken: {elapsed_time:.2f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745764264379,"user_tz":-330,"elapsed":1074,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"9a7a79cd-71f0-47c1-afcf-6a1f1ecab7a6","id":"qhuDT4hHcvhY"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NAME seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ID seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DATE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AGE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LOCATION seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONTACT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"]},{"output_type":"stream","name":"stdout","text":["Metrics computed using seqeval:\n","Accuracy: 0.99970703125\n","Precision: 0.9853768278965129\n","Recall: 0.9977220956719818\n","F1: 0.9915110356536503\n","\n","Detailed Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","         AME       1.00      1.00      1.00       200\n","         ATE       1.00      1.00      1.00       300\n","           D       1.00      1.00      1.00       100\n","          GE       0.85      0.97      0.91        78\n","     OCATION       1.00      1.00      1.00       100\n","      ONTACT       1.00      1.00      1.00       100\n","\n","   micro avg       0.99      1.00      0.99       878\n","   macro avg       0.98      1.00      0.99       878\n","weighted avg       0.99      1.00      0.99       878\n","\n","Time taken: 404.45 seconds\n"]}]},{"cell_type":"markdown","source":["# Batch size 8, Epochs 5, Learning rate = 1e-5"],"metadata":{"id":"0dZkthLCcxBQ"}},{"cell_type":"code","source":["# Step 10: Load model\n","model = AutoModelForTokenClassification.from_pretrained(\n","    model_checkpoint,\n","    num_labels=len(label_list),\n","    id2label=id2label,\n","    label2id=label2id\n",")"],"metadata":{"id":"DNo7noxQopUa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","# Start timer\n","start_time = time.time()\n","\n","# Step 11: Setup Data Collator\n","data_collator = DataCollatorForTokenClassification(\n","    tokenizer,\n","    padding=True,\n","    max_length=512,\n","    return_tensors=\"pt\"\n",")\n","\n","# Step 12: Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./kindlab_bert_deid_finetuned\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=5,\n","    learning_rate=1e-5,\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    save_steps=200,\n","    save_total_limit=2,\n","    remove_unused_columns=False\n",")\n","\n","# Step 13: Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")\n","\n","# Step 14: Train\n","trainer.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1745764678016,"user_tz":-330,"elapsed":406375,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"4c092d41-5238-4c6f-80ee-3c842748a707","id":"7uHJnHXQcxBQ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [500/500 06:44, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.193700</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.064400</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.027400</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.013200</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.006800</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.005200</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.002900</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.002500</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.002700</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.003000</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.001700</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.002200</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.002100</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.002000</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.001300</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.001200</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.001400</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.001500</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.001200</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.001200</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.001200</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.000700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=500, training_loss=0.007224588507786393, metrics={'train_runtime': 405.0872, 'train_samples_per_second': 9.874, 'train_steps_per_second': 1.234, 'total_flos': 1045243723776000.0, 'train_loss': 0.007224588507786393, 'epoch': 5.0})"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from transformers import DataCollatorForTokenClassification\n","from seqeval.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n","\n","small_test_dataset = dataset[\"test\"].select(range(100))\n","# Set up DataCollator\n","data_collator = DataCollatorForTokenClassification(tokenizer, padding=True, return_tensors=\"pt\")\n","test_dataloader = DataLoader(small_test_dataset, batch_size=8, collate_fn=data_collator)\n","\n","# Move model to device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.eval()\n","\n","all_preds = []\n","all_labels = []\n","\n","# Evaluate\n","with torch.no_grad():\n","    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        predictions = logits.argmax(dim=-1)\n","\n","        all_preds.append(predictions.cpu().numpy())\n","        all_labels.append(labels.cpu().numpy())\n","\n","# Stack all batches\n","all_preds = np.concatenate(all_preds, axis=0)\n","all_labels = np.concatenate(all_labels, axis=0)\n","\n","# Decode predictions\n","true_predictions = []\n","true_labels = []\n","\n","for prediction, label in zip(all_preds, all_labels):\n","    temp_pred = []\n","    temp_label = []\n","    for p, l in zip(prediction, label):\n","        if l == -100:\n","            continue\n","        temp_pred.append(id2label[p])\n","        temp_label.append(id2label[l])\n","    true_predictions.append(temp_pred)\n","    true_labels.append(temp_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745764680887,"user_tz":-330,"elapsed":2872,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"2678101f-599a-4ecf-ac5f-343db34fd560","id":"Iy3xflFwcxBR"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 13/13 [00:02<00:00,  4.39it/s]\n"]}]},{"cell_type":"code","source":["print(\"Metrics computed using seqeval:\")\n","print(\"Accuracy:\", accuracy_score(true_labels, true_predictions))\n","print(\"Precision:\", precision_score(true_labels, true_predictions))\n","print(\"Recall:\", recall_score(true_labels, true_predictions))\n","print(\"F1:\", f1_score(true_labels, true_predictions))\n","print(\"\\nDetailed Classification Report:\\n\")\n","print(classification_report(true_labels, true_predictions))\n","\n","# End timer\n","end_time = time.time()\n","\n","# Compute elapsed time\n","elapsed_time = end_time - start_time\n","\n","print(f\"Time taken: {elapsed_time:.2f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745764681664,"user_tz":-330,"elapsed":774,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"3d1e46f9-566e-4e81-c836-9a95bfc05410","id":"tAdkpDIicxBR"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NAME seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ID seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DATE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AGE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LOCATION seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONTACT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"]},{"output_type":"stream","name":"stdout","text":["Metrics computed using seqeval:\n","Accuracy: 0.99966796875\n","Precision: 0.9831649831649831\n","Recall: 0.9977220956719818\n","F1: 0.9903900508762012\n","\n","Detailed Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","         AME       1.00      1.00      1.00       200\n","         ATE       1.00      1.00      1.00       300\n","           D       1.00      1.00      1.00       100\n","          GE       0.84      0.97      0.90        78\n","     OCATION       1.00      1.00      1.00       100\n","      ONTACT       1.00      1.00      1.00       100\n","\n","   micro avg       0.98      1.00      0.99       878\n","   macro avg       0.97      1.00      0.98       878\n","weighted avg       0.99      1.00      0.99       878\n","\n","Time taken: 410.04 seconds\n"]}]},{"cell_type":"markdown","source":["# Batch size 8, Epochs 5, Learning rate = 1e-6"],"metadata":{"id":"_fQqV4HSoXNf"}},{"cell_type":"code","source":["# Step 10: Load model\n","model = AutoModelForTokenClassification.from_pretrained(\n","    model_checkpoint,\n","    num_labels=len(label_list),\n","    id2label=id2label,\n","    label2id=label2id\n",")"],"metadata":{"id":"Z4hH33Lyof0U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","# Start timer\n","start_time = time.time()\n","\n","# Step 11: Setup Data Collator\n","data_collator = DataCollatorForTokenClassification(\n","    tokenizer,\n","    padding=True,\n","    max_length=512,\n","    return_tensors=\"pt\"\n",")\n","\n","# Step 12: Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./kindlab_bert_deid_finetuned\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=5,\n","    learning_rate=1e-6,\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    save_steps=200,\n","    save_total_limit=2,\n","    remove_unused_columns=False\n",")\n","\n","# Step 13: Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")\n","\n","# Step 14: Train\n","trainer.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1745765109412,"user_tz":-330,"elapsed":405217,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"4cda55aa-d7c1-4c6a-8f78-aa3e6f84f14a","id":"ahl9fvi4oXNg"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [500/500 06:43, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.392800</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.283600</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.218500</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.174900</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.154800</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.135100</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.120400</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.115100</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.103600</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.096500</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.076800</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.068100</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.065300</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.048200</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.039600</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.053300</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.038100</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.033900</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.033300</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.030700</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.025800</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.025700</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.023800</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.025800</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.031200</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.026900</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.019100</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.017500</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.018100</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.018600</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.019600</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.015000</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.015200</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.015600</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.014200</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.014600</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.014500</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.015300</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.011200</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.016900</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.013500</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.012300</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.011000</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.011400</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.013100</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.012900</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.015300</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.011500</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.010900</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.012100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=500, training_loss=0.05581866376101971, metrics={'train_runtime': 404.2408, 'train_samples_per_second': 9.895, 'train_steps_per_second': 1.237, 'total_flos': 1045243723776000.0, 'train_loss': 0.05581866376101971, 'epoch': 5.0})"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from transformers import DataCollatorForTokenClassification\n","from seqeval.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n","\n","small_test_dataset = dataset[\"test\"].select(range(100))\n","# Set up DataCollator\n","data_collator = DataCollatorForTokenClassification(tokenizer, padding=True, return_tensors=\"pt\")\n","test_dataloader = DataLoader(small_test_dataset, batch_size=8, collate_fn=data_collator)\n","\n","# Move model to device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.eval()\n","\n","all_preds = []\n","all_labels = []\n","\n","# Evaluate\n","with torch.no_grad():\n","    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        predictions = logits.argmax(dim=-1)\n","\n","        all_preds.append(predictions.cpu().numpy())\n","        all_labels.append(labels.cpu().numpy())\n","\n","# Stack all batches\n","all_preds = np.concatenate(all_preds, axis=0)\n","all_labels = np.concatenate(all_labels, axis=0)\n","\n","# Decode predictions\n","true_predictions = []\n","true_labels = []\n","\n","for prediction, label in zip(all_preds, all_labels):\n","    temp_pred = []\n","    temp_label = []\n","    for p, l in zip(prediction, label):\n","        if l == -100:\n","            continue\n","        temp_pred.append(id2label[p])\n","        temp_label.append(id2label[l])\n","    true_predictions.append(temp_pred)\n","    true_labels.append(temp_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745765112169,"user_tz":-330,"elapsed":2891,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"54a22790-6437-4670-a3af-44347252b447","id":"01duuTAnoXNh"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 13/13 [00:02<00:00,  4.51it/s]\n"]}]},{"cell_type":"code","source":["print(\"Metrics computed using seqeval:\")\n","print(\"Accuracy:\", accuracy_score(true_labels, true_predictions))\n","print(\"Precision:\", precision_score(true_labels, true_predictions))\n","print(\"Recall:\", recall_score(true_labels, true_predictions))\n","print(\"F1:\", f1_score(true_labels, true_predictions))\n","print(\"\\nDetailed Classification Report:\\n\")\n","print(classification_report(true_labels, true_predictions))\n","\n","# End timer\n","end_time = time.time()\n","\n","# Compute elapsed time\n","elapsed_time = end_time - start_time\n","\n","print(f\"Time taken: {elapsed_time:.2f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745765112940,"user_tz":-330,"elapsed":764,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"bbd894c2-22bf-4483-9851-8c6c7f149d63","id":"PPR0Q3y0oXNi"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NAME seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ID seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DATE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AGE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LOCATION seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONTACT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"]},{"output_type":"stream","name":"stdout","text":["Metrics computed using seqeval:\n","Accuracy: 0.99830078125\n","Precision: 0.9298813376483279\n","Recall: 0.9817767653758542\n","F1: 0.9551246537396121\n","\n","Detailed Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","         AME       0.87      0.93      0.90       200\n","         ATE       1.00      1.00      1.00       300\n","           D       1.00      1.00      1.00       100\n","          GE       0.71      1.00      0.83        78\n","     OCATION       1.00      1.00      1.00       100\n","      ONTACT       0.95      0.98      0.97       100\n","\n","   micro avg       0.93      0.98      0.96       878\n","   macro avg       0.92      0.98      0.95       878\n","weighted avg       0.94      0.98      0.96       878\n","\n","Time taken: 408.77 seconds\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"nyxqGLAk9AwD"}},{"cell_type":"code","source":[],"metadata":{"id":"qucpl5Ug9A7E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Phase 2 Experiments, 1e-5, 5 Epochs with dynamic learning rate"],"metadata":{"id":"YjD7goOK-JzE"}},{"cell_type":"code","source":["# Step 10: Load model\n","model = AutoModelForTokenClassification.from_pretrained(\n","    model_checkpoint,\n","    num_labels=len(label_list),\n","    id2label=id2label,\n","    label2id=label2id\n",")"],"metadata":{"id":"fmJzgVG2-JzF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","# Start timer\n","start_time = time.time()\n","\n","# Step 11: Setup Data Collator\n","data_collator = DataCollatorForTokenClassification(\n","    tokenizer,\n","    padding=True,\n","    max_length=512,\n","    return_tensors=\"pt\"\n",")\n","\n","# Step 12: Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./kindlab_bert_deid_finetuned\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=5,\n","    learning_rate=1e-5,\n","    lr_scheduler_type=\"linear\",\n","    warmup_ratio=0.3,\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    save_steps=200,\n","    save_total_limit=2,\n","    remove_unused_columns=False\n",")\n","\n","# Step 13: Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")\n","\n","# Step 14: Train\n","trainer.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1745770234363,"user_tz":-330,"elapsed":491589,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"f53762cf-2d2d-49f2-d9bc-ae81e61daa94","id":"PULqmgqb-JzF"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msamyakjainuiuc\u001b[0m (\u001b[33msamyakjainuiuc-university-of-illionis-urbana-champaign\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.9"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/gdrive/MyDrive/wandb/run-20250427_160239-n5pny2nj</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/samyakjainuiuc-university-of-illionis-urbana-champaign/huggingface/runs/n5pny2nj' target=\"_blank\">./kindlab_bert_deid_finetuned</a></strong> to <a href='https://wandb.ai/samyakjainuiuc-university-of-illionis-urbana-champaign/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/samyakjainuiuc-university-of-illionis-urbana-champaign/huggingface' target=\"_blank\">https://wandb.ai/samyakjainuiuc-university-of-illionis-urbana-champaign/huggingface</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/samyakjainuiuc-university-of-illionis-urbana-champaign/huggingface/runs/n5pny2nj' target=\"_blank\">https://wandb.ai/samyakjainuiuc-university-of-illionis-urbana-champaign/huggingface/runs/n5pny2nj</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [500/500 07:49, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.427200</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.364800</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.252200</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.170600</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.126200</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.085900</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.041100</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.027300</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.017100</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.014100</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.005600</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.005400</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.004900</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.003700</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.003100</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.003100</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.002700</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.002500</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.001700</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.001500</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.001600</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.002000</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.001500</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.001300</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.001200</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.001600</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.001300</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.000800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=500, training_loss=0.03182210679817945, metrics={'train_runtime': 488.5453, 'train_samples_per_second': 8.188, 'train_steps_per_second': 1.023, 'total_flos': 1045243723776000.0, 'train_loss': 0.03182210679817945, 'epoch': 5.0})"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from transformers import DataCollatorForTokenClassification\n","from seqeval.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n","\n","small_test_dataset = dataset[\"test\"].select(range(100))\n","# Set up DataCollator\n","data_collator = DataCollatorForTokenClassification(tokenizer, padding=True, return_tensors=\"pt\")\n","test_dataloader = DataLoader(small_test_dataset, batch_size=8, collate_fn=data_collator)\n","\n","# Move model to device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.eval()\n","\n","all_preds = []\n","all_labels = []\n","\n","# Evaluate\n","with torch.no_grad():\n","    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        predictions = logits.argmax(dim=-1)\n","\n","        all_preds.append(predictions.cpu().numpy())\n","        all_labels.append(labels.cpu().numpy())\n","\n","# Stack all batches\n","all_preds = np.concatenate(all_preds, axis=0)\n","all_labels = np.concatenate(all_labels, axis=0)\n","\n","# Decode predictions\n","true_predictions = []\n","true_labels = []\n","\n","for prediction, label in zip(all_preds, all_labels):\n","    temp_pred = []\n","    temp_label = []\n","    for p, l in zip(prediction, label):\n","        if l == -100:\n","            continue\n","        temp_pred.append(id2label[p])\n","        temp_label.append(id2label[l])\n","    true_predictions.append(temp_pred)\n","    true_labels.append(temp_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745770237633,"user_tz":-330,"elapsed":3275,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"5f8c56a9-6e86-4fb9-ac3e-697931fa1f5c","id":"5onxFwOr-JzG"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 13/13 [00:03<00:00,  4.21it/s]\n"]}]},{"cell_type":"code","source":["print(\"Metrics computed using seqeval:\")\n","print(\"Accuracy:\", accuracy_score(true_labels, true_predictions))\n","print(\"Precision:\", precision_score(true_labels, true_predictions))\n","print(\"Recall:\", recall_score(true_labels, true_predictions))\n","print(\"F1:\", f1_score(true_labels, true_predictions))\n","print(\"\\nDetailed Classification Report:\\n\")\n","print(classification_report(true_labels, true_predictions))\n","\n","# End timer\n","end_time = time.time()\n","\n","# Compute elapsed time\n","elapsed_time = end_time - start_time\n","\n","print(f\"Time taken: {elapsed_time:.2f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745770240863,"user_tz":-330,"elapsed":3228,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"4216cc80-5254-422c-c567-81d3aeab72dc","id":"jQshhdVE-JzG"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Metrics computed using seqeval:\n","Accuracy: 0.9996484375\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NAME seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ID seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DATE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AGE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LOCATION seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONTACT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"]},{"output_type":"stream","name":"stdout","text":["Precision: 0.9820627802690582\n","Recall: 0.9977220956719818\n","F1: 0.9898305084745762\n","\n","Detailed Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","         AME       1.00      1.00      1.00       200\n","         ATE       1.00      1.00      1.00       300\n","           D       1.00      1.00      1.00       100\n","          GE       0.83      0.97      0.89        78\n","     OCATION       1.00      1.00      1.00       100\n","      ONTACT       1.00      1.00      1.00       100\n","\n","   micro avg       0.98      1.00      0.99       878\n","   macro avg       0.97      1.00      0.98       878\n","weighted avg       0.98      1.00      0.99       878\n","\n","Time taken: 498.10 seconds\n"]}]},{"cell_type":"markdown","source":["# Phase 2 Experiments, 1e-5, 7 Epochs with dynamic learning rate"],"metadata":{"id":"QwWa_PhT9uSh"}},{"cell_type":"code","source":["# Step 10: Load model\n","model = AutoModelForTokenClassification.from_pretrained(\n","    model_checkpoint,\n","    num_labels=len(label_list),\n","    id2label=id2label,\n","    label2id=label2id\n",")"],"metadata":{"id":"UEHfa-739uSi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","# Start timer\n","start_time = time.time()\n","\n","# Step 11: Setup Data Collator\n","data_collator = DataCollatorForTokenClassification(\n","    tokenizer,\n","    padding=True,\n","    max_length=512,\n","    return_tensors=\"pt\"\n",")\n","\n","# Step 12: Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./kindlab_bert_deid_finetuned\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=7,\n","    learning_rate=1e-5,\n","    lr_scheduler_type=\"linear\",\n","    warmup_ratio=0.3,\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    save_steps=200,\n","    save_total_limit=2,\n","    remove_unused_columns=False\n",")\n","\n","# Step 13: Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")\n","\n","# Step 14: Train\n","trainer.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1745770841658,"user_tz":-330,"elapsed":574089,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"9f0a3ccf-a2a5-4ac8-f065-c3754ed35b4f","id":"nZoiaQyZ9uSi"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='700' max='700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [700/700 09:32, Epoch 7/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.429000</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.383300</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.297100</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.197400</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.153300</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.114200</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.076900</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.045800</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.029700</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.024400</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.009500</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.008600</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.007500</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.005100</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.004600</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.005000</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.004200</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.003500</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.002300</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.001900</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.002100</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.002200</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.001400</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.001900</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.001300</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.001200</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.001700</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.001300</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.001600</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.000600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=700, training_loss=0.026434664853316334, metrics={'train_runtime': 573.3405, 'train_samples_per_second': 9.767, 'train_steps_per_second': 1.221, 'total_flos': 1463341213286400.0, 'train_loss': 0.026434664853316334, 'epoch': 7.0})"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from transformers import DataCollatorForTokenClassification\n","from seqeval.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n","\n","small_test_dataset = dataset[\"test\"].select(range(100))\n","# Set up DataCollator\n","data_collator = DataCollatorForTokenClassification(tokenizer, padding=True, return_tensors=\"pt\")\n","test_dataloader = DataLoader(small_test_dataset, batch_size=8, collate_fn=data_collator)\n","\n","# Move model to device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.eval()\n","\n","all_preds = []\n","all_labels = []\n","\n","# Evaluate\n","with torch.no_grad():\n","    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        predictions = logits.argmax(dim=-1)\n","\n","        all_preds.append(predictions.cpu().numpy())\n","        all_labels.append(labels.cpu().numpy())\n","\n","# Stack all batches\n","all_preds = np.concatenate(all_preds, axis=0)\n","all_labels = np.concatenate(all_labels, axis=0)\n","\n","# Decode predictions\n","true_predictions = []\n","true_labels = []\n","\n","for prediction, label in zip(all_preds, all_labels):\n","    temp_pred = []\n","    temp_label = []\n","    for p, l in zip(prediction, label):\n","        if l == -100:\n","            continue\n","        temp_pred.append(id2label[p])\n","        temp_label.append(id2label[l])\n","    true_predictions.append(temp_pred)\n","    true_labels.append(temp_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745770844640,"user_tz":-330,"elapsed":2981,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"83b3966e-484b-44e1-cfff-c3c624b9aae5","id":"KXnsIxyf9uSj"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 13/13 [00:02<00:00,  4.43it/s]\n"]}]},{"cell_type":"code","source":["print(\"Metrics computed using seqeval:\")\n","print(\"Accuracy:\", accuracy_score(true_labels, true_predictions))\n","print(\"Precision:\", precision_score(true_labels, true_predictions))\n","print(\"Recall:\", recall_score(true_labels, true_predictions))\n","print(\"F1:\", f1_score(true_labels, true_predictions))\n","print(\"\\nDetailed Classification Report:\\n\")\n","print(classification_report(true_labels, true_predictions))\n","\n","# End timer\n","end_time = time.time()\n","\n","# Compute elapsed time\n","elapsed_time = end_time - start_time\n","\n","print(f\"Time taken: {elapsed_time:.2f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745770845355,"user_tz":-330,"elapsed":714,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"b662e1d1-dc70-4d35-f4e1-7bbd085d512d","id":"Y0amsBE09uSj"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NAME seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ID seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DATE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AGE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LOCATION seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONTACT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"]},{"output_type":"stream","name":"stdout","text":["Metrics computed using seqeval:\n","Accuracy: 0.99966796875\n","Precision: 0.984251968503937\n","Recall: 0.9965831435079726\n","F1: 0.9903791737408036\n","\n","Detailed Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","         AME       1.00      1.00      1.00       200\n","         ATE       1.00      1.00      1.00       300\n","           D       1.00      1.00      1.00       100\n","          GE       0.84      0.96      0.90        78\n","     OCATION       1.00      1.00      1.00       100\n","      ONTACT       1.00      1.00      1.00       100\n","\n","   micro avg       0.98      1.00      0.99       878\n","   macro avg       0.97      0.99      0.98       878\n","weighted avg       0.99      1.00      0.99       878\n","\n","Time taken: 577.81 seconds\n"]}]},{"cell_type":"markdown","source":["# Phase 2 Experiments, 1e-5, 10 Epochs with dynamic learning rate"],"metadata":{"id":"D2qJDZcp9IK0"}},{"cell_type":"code","source":["# Step 10: Load model\n","model = AutoModelForTokenClassification.from_pretrained(\n","    model_checkpoint,\n","    num_labels=len(label_list),\n","    id2label=id2label,\n","    label2id=label2id\n",")"],"metadata":{"id":"_Ja9h0eX9IK1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","# Start timer\n","start_time = time.time()\n","\n","# Step 11: Setup Data Collator\n","data_collator = DataCollatorForTokenClassification(\n","    tokenizer,\n","    padding=True,\n","    max_length=512,\n","    return_tensors=\"pt\"\n",")\n","\n","# Step 12: Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./kindlab_bert_deid_finetuned\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=10,\n","    learning_rate=1e-5,\n","    lr_scheduler_type=\"linear\",\n","    warmup_ratio=0.3,\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    save_steps=200,\n","    save_total_limit=2,\n","    remove_unused_columns=False\n",")\n","\n","# Step 13: Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")\n","\n","# Step 14: Train\n","trainer.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1745771683735,"user_tz":-330,"elapsed":814457,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"a5e449de-bc2e-4f13-92c9-d45c417ce8ae","id":"PZD-l5DK9IK1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1000/1000 13:33, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.430300</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.396600</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.344100</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.235200</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.180700</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.142000</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.112000</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.087600</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.056400</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.038700</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.021600</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.016400</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.013300</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.008000</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.006800</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.008400</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.006600</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.005100</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.004000</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.003100</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.003100</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.001900</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.002700</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.002300</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.001300</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.002800</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.001600</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.001700</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.002100</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.001400</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.001400</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.001200</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.001300</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.001600</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.001200</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.001200</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.000600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1000, training_loss=0.02191794638428837, metrics={'train_runtime': 813.8262, 'train_samples_per_second': 9.83, 'train_steps_per_second': 1.229, 'total_flos': 2090487447552000.0, 'train_loss': 0.02191794638428837, 'epoch': 10.0})"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from transformers import DataCollatorForTokenClassification\n","from seqeval.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n","\n","small_test_dataset = dataset[\"test\"].select(range(100))\n","# Set up DataCollator\n","data_collator = DataCollatorForTokenClassification(tokenizer, padding=True, return_tensors=\"pt\")\n","test_dataloader = DataLoader(small_test_dataset, batch_size=8, collate_fn=data_collator)\n","\n","# Move model to device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.eval()\n","\n","all_preds = []\n","all_labels = []\n","\n","# Evaluate\n","with torch.no_grad():\n","    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        predictions = logits.argmax(dim=-1)\n","\n","        all_preds.append(predictions.cpu().numpy())\n","        all_labels.append(labels.cpu().numpy())\n","\n","# Stack all batches\n","all_preds = np.concatenate(all_preds, axis=0)\n","all_labels = np.concatenate(all_labels, axis=0)\n","\n","# Decode predictions\n","true_predictions = []\n","true_labels = []\n","\n","for prediction, label in zip(all_preds, all_labels):\n","    temp_pred = []\n","    temp_label = []\n","    for p, l in zip(prediction, label):\n","        if l == -100:\n","            continue\n","        temp_pred.append(id2label[p])\n","        temp_label.append(id2label[l])\n","    true_predictions.append(temp_pred)\n","    true_labels.append(temp_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745771686676,"user_tz":-330,"elapsed":2939,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"048518c5-a17e-48c1-c35c-aac1b21d4d31","id":"vECzgmA49IK2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 13/13 [00:02<00:00,  4.50it/s]\n"]}]},{"cell_type":"code","source":["print(\"Metrics computed using seqeval:\")\n","print(\"Accuracy:\", accuracy_score(true_labels, true_predictions))\n","print(\"Precision:\", precision_score(true_labels, true_predictions))\n","print(\"Recall:\", recall_score(true_labels, true_predictions))\n","print(\"F1:\", f1_score(true_labels, true_predictions))\n","print(\"\\nDetailed Classification Report:\\n\")\n","print(classification_report(true_labels, true_predictions))\n","\n","# End timer\n","end_time = time.time()\n","\n","# Compute elapsed time\n","elapsed_time = end_time - start_time\n","\n","print(f\"Time taken: {elapsed_time:.2f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745771687440,"user_tz":-330,"elapsed":762,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"2c7655ec-5dc5-4283-d723-dadbc405beec","id":"Ik1SCn-99IK2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NAME seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ID seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DATE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AGE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LOCATION seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONTACT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"]},{"output_type":"stream","name":"stdout","text":["Metrics computed using seqeval:\n","Accuracy: 0.99966796875\n","Precision: 0.9820828667413214\n","Recall: 0.9988610478359908\n","F1: 0.9904009034443816\n","\n","Detailed Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","         AME       1.00      1.00      1.00       200\n","         ATE       1.00      1.00      1.00       300\n","           D       1.00      1.00      1.00       100\n","          GE       0.83      0.99      0.90        78\n","     OCATION       1.00      1.00      1.00       100\n","      ONTACT       1.00      1.00      1.00       100\n","\n","   micro avg       0.98      1.00      0.99       878\n","   macro avg       0.97      1.00      0.98       878\n","weighted avg       0.98      1.00      0.99       878\n","\n","Time taken: 818.18 seconds\n"]}]},{"cell_type":"markdown","source":["# Phase 2 Experiments, 2e-5, 5 Epochs with dynamic learning rate"],"metadata":{"id":"zx2798dNpkiI"}},{"cell_type":"code","source":["# Step 10: Load model\n","model = AutoModelForTokenClassification.from_pretrained(\n","    model_checkpoint,\n","    num_labels=len(label_list),\n","    id2label=id2label,\n","    label2id=label2id\n",")"],"metadata":{"id":"YGoE7IacpkiJ","executionInfo":{"status":"ok","timestamp":1745848374643,"user_tz":-330,"elapsed":654,"user":{"displayName":"Samyak","userId":"04413159794314589556"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","# Start timer\n","start_time = time.time()\n","\n","# Step 11: Setup Data Collator\n","data_collator = DataCollatorForTokenClassification(\n","    tokenizer,\n","    padding=True,\n","    max_length=512,\n","    return_tensors=\"pt\"\n",")\n","\n","# Step 12: Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./kindlab_bert_deid_finetuned\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=5,\n","    learning_rate=2e-5,\n","    lr_scheduler_type=\"linear\",\n","    warmup_ratio=0.3,\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    save_steps=200,\n","    save_total_limit=2,\n","    remove_unused_columns=False\n",")\n","\n","# Step 13: Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")\n","\n","# Step 14: Train\n","trainer.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1745848821197,"user_tz":-330,"elapsed":446556,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"7e020856-7ff8-423f-d7f6-8128ec043b87","id":"iK0WfR5kpkiJ"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msamyakjainuiuc\u001b[0m (\u001b[33msamyakjainuiuc-university-of-illionis-urbana-champaign\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.9"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/gdrive/MyDrive/wandb/run-20250428_135309-vi86qv88</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/samyakjainuiuc-university-of-illionis-urbana-champaign/huggingface/runs/vi86qv88' target=\"_blank\">./kindlab_bert_deid_finetuned</a></strong> to <a href='https://wandb.ai/samyakjainuiuc-university-of-illionis-urbana-champaign/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/samyakjainuiuc-university-of-illionis-urbana-champaign/huggingface' target=\"_blank\">https://wandb.ai/samyakjainuiuc-university-of-illionis-urbana-champaign/huggingface</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/samyakjainuiuc-university-of-illionis-urbana-champaign/huggingface/runs/vi86qv88' target=\"_blank\">https://wandb.ai/samyakjainuiuc-university-of-illionis-urbana-champaign/huggingface/runs/vi86qv88</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [500/500 07:05, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.420500</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.295900</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.187300</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.125000</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.068100</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.028800</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.011700</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.007200</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.005800</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.004800</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.002200</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.002600</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.002300</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.002200</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.001500</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.001200</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.001400</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.001500</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.001300</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.000700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=500, training_loss=0.023866761840879918, metrics={'train_runtime': 442.3822, 'train_samples_per_second': 9.042, 'train_steps_per_second': 1.13, 'total_flos': 1045243723776000.0, 'train_loss': 0.023866761840879918, 'epoch': 5.0})"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from transformers import DataCollatorForTokenClassification\n","from seqeval.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n","\n","small_test_dataset = dataset[\"test\"].select(range(100))\n","# Set up DataCollator\n","data_collator = DataCollatorForTokenClassification(tokenizer, padding=True, return_tensors=\"pt\")\n","test_dataloader = DataLoader(small_test_dataset, batch_size=8, collate_fn=data_collator)\n","\n","# Move model to device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.eval()\n","\n","all_preds = []\n","all_labels = []\n","\n","# Evaluate\n","with torch.no_grad():\n","    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        predictions = logits.argmax(dim=-1)\n","\n","        all_preds.append(predictions.cpu().numpy())\n","        all_labels.append(labels.cpu().numpy())\n","\n","# Stack all batches\n","all_preds = np.concatenate(all_preds, axis=0)\n","all_labels = np.concatenate(all_labels, axis=0)\n","\n","# Decode predictions\n","true_predictions = []\n","true_labels = []\n","\n","for prediction, label in zip(all_preds, all_labels):\n","    temp_pred = []\n","    temp_label = []\n","    for p, l in zip(prediction, label):\n","        if l == -100:\n","            continue\n","        temp_pred.append(id2label[p])\n","        temp_label.append(id2label[l])\n","    true_predictions.append(temp_pred)\n","    true_labels.append(temp_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745848824278,"user_tz":-330,"elapsed":3091,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"1a4d4d1a-39a0-4b6f-96ab-93b4a9173f61","id":"I7Yb-vJOpkiK"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 13/13 [00:03<00:00,  4.26it/s]\n"]}]},{"cell_type":"code","source":["print(\"Metrics computed using seqeval:\")\n","print(\"Accuracy:\", accuracy_score(true_labels, true_predictions))\n","print(\"Precision:\", precision_score(true_labels, true_predictions))\n","print(\"Recall:\", recall_score(true_labels, true_predictions))\n","print(\"F1:\", f1_score(true_labels, true_predictions))\n","print(\"\\nDetailed Classification Report:\\n\")\n","print(classification_report(true_labels, true_predictions))\n","\n","# End timer\n","end_time = time.time()\n","\n","# Compute elapsed time\n","elapsed_time = end_time - start_time\n","\n","print(f\"Time taken: {elapsed_time:.2f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745848825591,"user_tz":-330,"elapsed":1309,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"c75905b2-5ede-4a07-894c-210b2a53b530","id":"Va3miMfBpkiL"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NAME seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ID seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DATE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AGE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LOCATION seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONTACT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"]},{"output_type":"stream","name":"stdout","text":["Metrics computed using seqeval:\n","Accuracy: 0.99970703125\n","Precision: 0.9853768278965129\n","Recall: 0.9977220956719818\n","F1: 0.9915110356536503\n","\n","Detailed Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","         AME       1.00      1.00      1.00       200\n","         ATE       1.00      1.00      1.00       300\n","           D       1.00      1.00      1.00       100\n","          GE       0.85      0.97      0.91        78\n","     OCATION       1.00      1.00      1.00       100\n","      ONTACT       1.00      1.00      1.00       100\n","\n","   micro avg       0.99      1.00      0.99       878\n","   macro avg       0.98      1.00      0.99       878\n","weighted avg       0.99      1.00      0.99       878\n","\n","Time taken: 450.93 seconds\n"]}]},{"cell_type":"markdown","source":["# Phase 2 Experiments, 2e-5, 7 Epochs with dynamic learning rate"],"metadata":{"id":"JY0k-H2_plnJ"}},{"cell_type":"code","source":["# Step 10: Load model\n","model = AutoModelForTokenClassification.from_pretrained(\n","    model_checkpoint,\n","    num_labels=len(label_list),\n","    id2label=id2label,\n","    label2id=label2id\n",")"],"metadata":{"id":"Rv9ioLsTplnK","executionInfo":{"status":"ok","timestamp":1745848826136,"user_tz":-330,"elapsed":540,"user":{"displayName":"Samyak","userId":"04413159794314589556"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","# Start timer\n","start_time = time.time()\n","\n","# Step 11: Setup Data Collator\n","data_collator = DataCollatorForTokenClassification(\n","    tokenizer,\n","    padding=True,\n","    max_length=512,\n","    return_tensors=\"pt\"\n",")\n","\n","# Step 12: Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./kindlab_bert_deid_finetuned\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=7,\n","    learning_rate=2e-5,\n","    lr_scheduler_type=\"linear\",\n","    warmup_ratio=0.3,\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    save_steps=200,\n","    save_total_limit=2,\n","    remove_unused_columns=False\n",")\n","\n","# Step 13: Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")\n","\n","# Step 14: Train\n","trainer.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1745849423456,"user_tz":-330,"elapsed":597315,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"bc5d038f-7df4-4bae-ae25-69d234e8dda6","id":"17731ixjplnK"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='700' max='700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [700/700 09:55, Epoch 7/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.424400</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.335900</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.214300</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.147500</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.098200</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.050500</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.021600</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.013200</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.009800</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.003300</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.003600</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.003200</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.002900</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.002000</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.001700</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.001700</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.001800</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.001300</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.001200</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.001400</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.001300</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.000400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=700, training_loss=0.01973340507463685, metrics={'train_runtime': 596.6076, 'train_samples_per_second': 9.386, 'train_steps_per_second': 1.173, 'total_flos': 1463341213286400.0, 'train_loss': 0.01973340507463685, 'epoch': 7.0})"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from transformers import DataCollatorForTokenClassification\n","from seqeval.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n","\n","small_test_dataset = dataset[\"test\"].select(range(100))\n","# Set up DataCollator\n","data_collator = DataCollatorForTokenClassification(tokenizer, padding=True, return_tensors=\"pt\")\n","test_dataloader = DataLoader(small_test_dataset, batch_size=8, collate_fn=data_collator)\n","\n","# Move model to device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.eval()\n","\n","all_preds = []\n","all_labels = []\n","\n","# Evaluate\n","with torch.no_grad():\n","    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        predictions = logits.argmax(dim=-1)\n","\n","        all_preds.append(predictions.cpu().numpy())\n","        all_labels.append(labels.cpu().numpy())\n","\n","# Stack all batches\n","all_preds = np.concatenate(all_preds, axis=0)\n","all_labels = np.concatenate(all_labels, axis=0)\n","\n","# Decode predictions\n","true_predictions = []\n","true_labels = []\n","\n","for prediction, label in zip(all_preds, all_labels):\n","    temp_pred = []\n","    temp_label = []\n","    for p, l in zip(prediction, label):\n","        if l == -100:\n","            continue\n","        temp_pred.append(id2label[p])\n","        temp_label.append(id2label[l])\n","    true_predictions.append(temp_pred)\n","    true_labels.append(temp_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745849426545,"user_tz":-330,"elapsed":3075,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"03c87a82-5c43-40cc-e579-378ac850fea2","id":"zEdbh3f6plnK"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 13/13 [00:03<00:00,  4.28it/s]\n"]}]},{"cell_type":"code","source":["print(\"Metrics computed using seqeval:\")\n","print(\"Accuracy:\", accuracy_score(true_labels, true_predictions))\n","print(\"Precision:\", precision_score(true_labels, true_predictions))\n","print(\"Recall:\", recall_score(true_labels, true_predictions))\n","print(\"F1:\", f1_score(true_labels, true_predictions))\n","print(\"\\nDetailed Classification Report:\\n\")\n","print(classification_report(true_labels, true_predictions))\n","\n","# End timer\n","end_time = time.time()\n","\n","# Compute elapsed time\n","elapsed_time = end_time - start_time\n","\n","print(f\"Time taken: {elapsed_time:.2f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745849427886,"user_tz":-330,"elapsed":1339,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"53578be7-013a-4443-f6ec-81131450b6dc","id":"le-pHeXHplnL"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NAME seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ID seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DATE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AGE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LOCATION seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONTACT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"]},{"output_type":"stream","name":"stdout","text":["Metrics computed using seqeval:\n","Accuracy: 0.9996875\n","Precision: 0.9853603603603603\n","Recall: 0.9965831435079726\n","F1: 0.9909399773499433\n","\n","Detailed Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","         AME       1.00      1.00      1.00       200\n","         ATE       1.00      1.00      1.00       300\n","           D       1.00      1.00      1.00       100\n","          GE       0.85      0.96      0.90        78\n","     OCATION       1.00      1.00      1.00       100\n","      ONTACT       1.00      1.00      1.00       100\n","\n","   micro avg       0.99      1.00      0.99       878\n","   macro avg       0.98      0.99      0.98       878\n","weighted avg       0.99      1.00      0.99       878\n","\n","Time taken: 601.73 seconds\n"]}]},{"cell_type":"markdown","source":["# Phase 2 Experiments, 2e-5, 10 Epochs with dynamic learning rate"],"metadata":{"id":"4dVvrptJo4Yi"}},{"cell_type":"code","source":["# Step 10: Load model\n","model = AutoModelForTokenClassification.from_pretrained(\n","    model_checkpoint,\n","    num_labels=len(label_list),\n","    id2label=id2label,\n","    label2id=label2id\n",")"],"metadata":{"id":"kE2hSf2zo4Yj","executionInfo":{"status":"ok","timestamp":1745849428467,"user_tz":-330,"elapsed":584,"user":{"displayName":"Samyak","userId":"04413159794314589556"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","# Start timer\n","start_time = time.time()\n","\n","# Step 11: Setup Data Collator\n","data_collator = DataCollatorForTokenClassification(\n","    tokenizer,\n","    padding=True,\n","    max_length=512,\n","    return_tensors=\"pt\"\n",")\n","\n","# Step 12: Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./kindlab_bert_deid_finetuned\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=10,\n","    learning_rate=2e-5,\n","    lr_scheduler_type=\"linear\",\n","    warmup_ratio=0.3,\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    save_steps=200,\n","    save_total_limit=2,\n","    remove_unused_columns=False\n",")\n","\n","# Step 13: Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")\n","\n","# Step 14: Train\n","trainer.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1745850267096,"user_tz":-330,"elapsed":838625,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"e3fcedd9-01aa-462b-ec8b-65c7f2a9c46d","id":"GKdAimkKo4Yk"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1000/1000 13:57, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.427200</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.364800</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.252200</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.170600</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.126200</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.085900</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.041100</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.027300</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.017100</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.014100</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.005600</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.005400</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.004900</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.003700</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.003100</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.003100</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.002700</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.002500</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.001600</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.001500</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.001400</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.001800</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.001200</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.001300</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.001200</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.001400</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.000300</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.000600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1000, training_loss=0.016177289169514553, metrics={'train_runtime': 837.372, 'train_samples_per_second': 9.554, 'train_steps_per_second': 1.194, 'total_flos': 2090487447552000.0, 'train_loss': 0.016177289169514553, 'epoch': 10.0})"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from transformers import DataCollatorForTokenClassification\n","from seqeval.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n","\n","small_test_dataset = dataset[\"test\"].select(range(100))\n","# Set up DataCollator\n","data_collator = DataCollatorForTokenClassification(tokenizer, padding=True, return_tensors=\"pt\")\n","test_dataloader = DataLoader(small_test_dataset, batch_size=8, collate_fn=data_collator)\n","\n","# Move model to device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.eval()\n","\n","all_preds = []\n","all_labels = []\n","\n","# Evaluate\n","with torch.no_grad():\n","    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        predictions = logits.argmax(dim=-1)\n","\n","        all_preds.append(predictions.cpu().numpy())\n","        all_labels.append(labels.cpu().numpy())\n","\n","# Stack all batches\n","all_preds = np.concatenate(all_preds, axis=0)\n","all_labels = np.concatenate(all_labels, axis=0)\n","\n","# Decode predictions\n","true_predictions = []\n","true_labels = []\n","\n","for prediction, label in zip(all_preds, all_labels):\n","    temp_pred = []\n","    temp_label = []\n","    for p, l in zip(prediction, label):\n","        if l == -100:\n","            continue\n","        temp_pred.append(id2label[p])\n","        temp_label.append(id2label[l])\n","    true_predictions.append(temp_pred)\n","    true_labels.append(temp_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745850270094,"user_tz":-330,"elapsed":2997,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"3ff2dee3-62c7-4fd9-cb97-d2c3a804757d","id":"uHDgrygWo4Ym"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 13/13 [00:02<00:00,  4.38it/s]\n"]}]},{"cell_type":"code","source":["print(\"Metrics computed using seqeval:\")\n","print(\"Accuracy:\", accuracy_score(true_labels, true_predictions))\n","print(\"Precision:\", precision_score(true_labels, true_predictions))\n","print(\"Recall:\", recall_score(true_labels, true_predictions))\n","print(\"F1:\", f1_score(true_labels, true_predictions))\n","print(\"\\nDetailed Classification Report:\\n\")\n","print(classification_report(true_labels, true_predictions))\n","\n","# End timer\n","end_time = time.time()\n","\n","# Compute elapsed time\n","elapsed_time = end_time - start_time\n","\n","print(f\"Time taken: {elapsed_time:.2f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745850270917,"user_tz":-330,"elapsed":822,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"85dd2521-acc3-4262-ef04-512ce00d4a44","id":"Ox9Fn_jOo4Yn"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NAME seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ID seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DATE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AGE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LOCATION seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONTACT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"]},{"output_type":"stream","name":"stdout","text":["Metrics computed using seqeval:\n","Accuracy: 0.9996875\n","Precision: 0.9831838565022422\n","Recall: 0.9988610478359908\n","F1: 0.9909604519774012\n","\n","Detailed Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","         AME       1.00      1.00      1.00       200\n","         ATE       1.00      1.00      1.00       300\n","           D       1.00      1.00      1.00       100\n","          GE       0.84      0.99      0.91        78\n","     OCATION       1.00      1.00      1.00       100\n","      ONTACT       1.00      1.00      1.00       100\n","\n","   micro avg       0.98      1.00      0.99       878\n","   macro avg       0.97      1.00      0.98       878\n","weighted avg       0.99      1.00      0.99       878\n","\n","Time taken: 842.43 seconds\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"Q1ZomZSAzhDO"}},{"cell_type":"markdown","source":["# Phase 2 Experiments, 2e-5, 5 Epochs with COSINE learning rate"],"metadata":{"id":"C4e-35nm-ZG_"}},{"cell_type":"code","source":["# Step 10: Load model\n","model = AutoModelForTokenClassification.from_pretrained(\n","    model_checkpoint,\n","    num_labels=len(label_list),\n","    id2label=id2label,\n","    label2id=label2id\n",")"],"metadata":{"id":"6yoDpLCz-ZHA","executionInfo":{"status":"ok","timestamp":1745853773294,"user_tz":-330,"elapsed":547,"user":{"displayName":"Samyak","userId":"04413159794314589556"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","# Start timer\n","start_time = time.time()\n","\n","# Step 11: Setup Data Collator\n","data_collator = DataCollatorForTokenClassification(\n","    tokenizer,\n","    padding=True,\n","    max_length=512,\n","    return_tensors=\"pt\"\n",")\n","\n","# Step 12: Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./kindlab_bert_deid_finetuned\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=5,\n","    learning_rate=2e-5,\n","    lr_scheduler_type=\"cosine\",\n","    warmup_ratio=0.3,\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    save_steps=200,\n","    save_total_limit=2,\n","    remove_unused_columns=False\n",")\n","\n","# Step 13: Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")\n","\n","# Step 14: Train\n","trainer.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1745854209939,"user_tz":-330,"elapsed":436646,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"062e9c5d-18eb-471d-e36d-6360d976be3d","id":"eTpWosNC-ZHA"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msamyakjainuiuc\u001b[0m (\u001b[33msamyakjainuiuc-university-of-illionis-urbana-champaign\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.9"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/gdrive/MyDrive/wandb/run-20250428_152309-gsxruem5</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/samyakjainuiuc-university-of-illionis-urbana-champaign/huggingface/runs/gsxruem5' target=\"_blank\">./kindlab_bert_deid_finetuned</a></strong> to <a href='https://wandb.ai/samyakjainuiuc-university-of-illionis-urbana-champaign/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/samyakjainuiuc-university-of-illionis-urbana-champaign/huggingface' target=\"_blank\">https://wandb.ai/samyakjainuiuc-university-of-illionis-urbana-champaign/huggingface</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/samyakjainuiuc-university-of-illionis-urbana-champaign/huggingface/runs/gsxruem5' target=\"_blank\">https://wandb.ai/samyakjainuiuc-university-of-illionis-urbana-champaign/huggingface/runs/gsxruem5</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [500/500 06:52, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.420500</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.295900</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.187300</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.125000</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.068100</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.028800</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.011700</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.007200</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.005800</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.004800</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.002200</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.002600</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.002300</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.002200</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.001500</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.001200</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.001300</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.001500</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.001300</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.000700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=500, training_loss=0.02386358405277133, metrics={'train_runtime': 431.6318, 'train_samples_per_second': 9.267, 'train_steps_per_second': 1.158, 'total_flos': 1045243723776000.0, 'train_loss': 0.02386358405277133, 'epoch': 5.0})"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from transformers import DataCollatorForTokenClassification\n","from seqeval.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n","\n","small_test_dataset = dataset[\"test\"].select(range(100))\n","# Set up DataCollator\n","data_collator = DataCollatorForTokenClassification(tokenizer, padding=True, return_tensors=\"pt\")\n","test_dataloader = DataLoader(small_test_dataset, batch_size=8, collate_fn=data_collator)\n","\n","# Move model to device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.eval()\n","\n","all_preds = []\n","all_labels = []\n","\n","# Evaluate\n","with torch.no_grad():\n","    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        predictions = logits.argmax(dim=-1)\n","\n","        all_preds.append(predictions.cpu().numpy())\n","        all_labels.append(labels.cpu().numpy())\n","\n","# Stack all batches\n","all_preds = np.concatenate(all_preds, axis=0)\n","all_labels = np.concatenate(all_labels, axis=0)\n","\n","# Decode predictions\n","true_predictions = []\n","true_labels = []\n","\n","for prediction, label in zip(all_preds, all_labels):\n","    temp_pred = []\n","    temp_label = []\n","    for p, l in zip(prediction, label):\n","        if l == -100:\n","            continue\n","        temp_pred.append(id2label[p])\n","        temp_label.append(id2label[l])\n","    true_predictions.append(temp_pred)\n","    true_labels.append(temp_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745854212869,"user_tz":-330,"elapsed":2928,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"de4c0a82-90dd-4155-d97e-61e788840195","id":"TNNjbftp-ZHA"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 13/13 [00:02<00:00,  4.55it/s]\n"]}]},{"cell_type":"code","source":["print(\"Metrics computed using seqeval:\")\n","print(\"Accuracy:\", accuracy_score(true_labels, true_predictions))\n","print(\"Precision:\", precision_score(true_labels, true_predictions))\n","print(\"Recall:\", recall_score(true_labels, true_predictions))\n","print(\"F1:\", f1_score(true_labels, true_predictions))\n","print(\"\\nDetailed Classification Report:\\n\")\n","print(classification_report(true_labels, true_predictions))\n","\n","# End timer\n","end_time = time.time()\n","\n","# Compute elapsed time\n","elapsed_time = end_time - start_time\n","\n","print(f\"Time taken: {elapsed_time:.2f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745854214169,"user_tz":-330,"elapsed":1299,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"a2b5fbbe-193b-4565-a146-6532fdfc7a87","id":"X_9yNJ_L-ZHB"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NAME seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ID seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DATE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AGE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LOCATION seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONTACT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"]},{"output_type":"stream","name":"stdout","text":["Metrics computed using seqeval:\n","Accuracy: 0.9996875\n","Precision: 0.9853603603603603\n","Recall: 0.9965831435079726\n","F1: 0.9909399773499433\n","\n","Detailed Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","         AME       1.00      1.00      1.00       200\n","         ATE       1.00      1.00      1.00       300\n","           D       1.00      1.00      1.00       100\n","          GE       0.85      0.96      0.90        78\n","     OCATION       1.00      1.00      1.00       100\n","      ONTACT       1.00      1.00      1.00       100\n","\n","   micro avg       0.99      1.00      0.99       878\n","   macro avg       0.98      0.99      0.98       878\n","weighted avg       0.99      1.00      0.99       878\n","\n","Time taken: 440.89 seconds\n"]}]},{"cell_type":"markdown","source":["# Phase 2 Experiments, 2e-5, 5 Epochs with fixed learning rate and weight decay"],"metadata":{"id":"uyJdqKfRzhjK"}},{"cell_type":"code","source":["# Step 10: Load model\n","model = AutoModelForTokenClassification.from_pretrained(\n","    model_checkpoint,\n","    num_labels=len(label_list),\n","    id2label=id2label,\n","    label2id=label2id\n",")"],"metadata":{"executionInfo":{"status":"ok","timestamp":1745854254356,"user_tz":-330,"elapsed":1043,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"id":"axkAJcqjzhjL"},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","# Start timer\n","start_time = time.time()\n","\n","# Step 11: Setup Data Collator\n","data_collator = DataCollatorForTokenClassification(\n","    tokenizer,\n","    padding=True,\n","    max_length=512,\n","    return_tensors=\"pt\"\n",")\n","\n","# Step 12: Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./kindlab_bert_deid_finetuned\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=5,\n","    learning_rate=2e-5,\n","    weight_decay=0.01,\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    save_steps=200,\n","    save_total_limit=2,\n","    remove_unused_columns=False\n",")\n","\n","# Step 13: Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")\n","\n","# Step 14: Train\n","trainer.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1745854665099,"user_tz":-330,"elapsed":410744,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"14fc8e7d-9ef1-4ecf-a8ad-8edecec79d0d","id":"jUZw175WzhjL"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [500/500 06:48, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.136600</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.019300</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.007300</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.004500</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.002200</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.001800</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.001200</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.001300</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.001200</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.000300</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.000700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=500, training_loss=0.004089230146259069, metrics={'train_runtime': 409.4137, 'train_samples_per_second': 9.77, 'train_steps_per_second': 1.221, 'total_flos': 1045243723776000.0, 'train_loss': 0.004089230146259069, 'epoch': 5.0})"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from transformers import DataCollatorForTokenClassification\n","from seqeval.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n","\n","small_test_dataset = dataset[\"test\"].select(range(100))\n","# Set up DataCollator\n","data_collator = DataCollatorForTokenClassification(tokenizer, padding=True, return_tensors=\"pt\")\n","test_dataloader = DataLoader(small_test_dataset, batch_size=8, collate_fn=data_collator)\n","\n","# Move model to device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.eval()\n","\n","all_preds = []\n","all_labels = []\n","\n","# Evaluate\n","with torch.no_grad():\n","    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        predictions = logits.argmax(dim=-1)\n","\n","        all_preds.append(predictions.cpu().numpy())\n","        all_labels.append(labels.cpu().numpy())\n","\n","# Stack all batches\n","all_preds = np.concatenate(all_preds, axis=0)\n","all_labels = np.concatenate(all_labels, axis=0)\n","\n","# Decode predictions\n","true_predictions = []\n","true_labels = []\n","\n","for prediction, label in zip(all_preds, all_labels):\n","    temp_pred = []\n","    temp_label = []\n","    for p, l in zip(prediction, label):\n","        if l == -100:\n","            continue\n","        temp_pred.append(id2label[p])\n","        temp_label.append(id2label[l])\n","    true_predictions.append(temp_pred)\n","    true_labels.append(temp_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745854668066,"user_tz":-330,"elapsed":2967,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"56326b87-c906-437c-ba1f-ccc802d2b574","id":"6SQgagBFzhjM"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 13/13 [00:02<00:00,  4.47it/s]\n"]}]},{"cell_type":"code","source":["print(\"Metrics computed using seqeval:\")\n","print(\"Accuracy:\", accuracy_score(true_labels, true_predictions))\n","print(\"Precision:\", precision_score(true_labels, true_predictions))\n","print(\"Recall:\", recall_score(true_labels, true_predictions))\n","print(\"F1:\", f1_score(true_labels, true_predictions))\n","print(\"\\nDetailed Classification Report:\\n\")\n","print(classification_report(true_labels, true_predictions))\n","\n","# End timer\n","end_time = time.time()\n","\n","# Compute elapsed time\n","elapsed_time = end_time - start_time\n","\n","print(f\"Time taken: {elapsed_time:.2f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745854668781,"user_tz":-330,"elapsed":714,"user":{"displayName":"Samyak","userId":"04413159794314589556"}},"outputId":"2cd0d64f-5e68-4103-b8ee-e921b84f29d5","id":"S29QkwRTzhjM"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NAME seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ID seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DATE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AGE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LOCATION seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONTACT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"]},{"output_type":"stream","name":"stdout","text":["Metrics computed using seqeval:\n","Accuracy: 0.99970703125\n","Precision: 0.9853768278965129\n","Recall: 0.9977220956719818\n","F1: 0.9915110356536503\n","\n","Detailed Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","         AME       1.00      1.00      1.00       200\n","         ATE       1.00      1.00      1.00       300\n","           D       1.00      1.00      1.00       100\n","          GE       0.85      0.97      0.91        78\n","     OCATION       1.00      1.00      1.00       100\n","      ONTACT       1.00      1.00      1.00       100\n","\n","   micro avg       0.99      1.00      0.99       878\n","   macro avg       0.98      1.00      0.99       878\n","weighted avg       0.99      1.00      0.99       878\n","\n","Time taken: 414.45 seconds\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1PmZcntp5Lo-Qv6fIXFENLyO2RTKw7vHU","timestamp":1745736712204},{"file_id":"1pueKYiw5E5uaLR5ay51mMOP3bxkIitMj","timestamp":1745666452131}],"gpuType":"T4","collapsed_sections":["0lm9Gecibif2","AgjE4tuHcfoM","BkdD3Jl1csyM","GokDwUUyctx4","re7F2BGtcuqu","ififpv3NcvhX","0dZkthLCcxBQ","_fQqV4HSoXNf","YjD7goOK-JzE","QwWa_PhT9uSh","D2qJDZcp9IK0","zx2798dNpkiI","JY0k-H2_plnJ","C4e-35nm-ZG_"],"authorship_tag":"ABX9TyPXNl0WUoiuyrOqFOYAl0Sz"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6b29739ab2f6449481164397c276a13c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_01a1e2882b9c4e509bf2ebd7319561d5","IPY_MODEL_24a8cf53d67648a79639b87bd08f57aa","IPY_MODEL_35340730c7c341858b6dec4fb787c18b"],"layout":"IPY_MODEL_382dbf1cb8dc4c868c5f2e0036a65ef1"}},"01a1e2882b9c4e509bf2ebd7319561d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f0f66de5a2a40368dfbbe865b7ab194","placeholder":"​","style":"IPY_MODEL_1031406125974255bfab9510b0207082","value":"tokenizer_config.json: 100%"}},"24a8cf53d67648a79639b87bd08f57aa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6cd6cba0f6ad4d739bb3834f30ae3ec7","max":49,"min":0,"orientation":"horizontal","style":"IPY_MODEL_67bb766165d64af4b8efae4a5dbe4c04","value":49}},"35340730c7c341858b6dec4fb787c18b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4d5b04d5ec642768c791ede5530c8eb","placeholder":"​","style":"IPY_MODEL_bbe4ac5298c74d6ea214f5b19c46b2c3","value":" 49.0/49.0 [00:00&lt;00:00, 5.15kB/s]"}},"382dbf1cb8dc4c868c5f2e0036a65ef1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f0f66de5a2a40368dfbbe865b7ab194":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1031406125974255bfab9510b0207082":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6cd6cba0f6ad4d739bb3834f30ae3ec7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67bb766165d64af4b8efae4a5dbe4c04":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e4d5b04d5ec642768c791ede5530c8eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbe4ac5298c74d6ea214f5b19c46b2c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2845e1c473fb4b0d8d481864fba771be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b74cb9d12ca24301a0dd90e2e78b3046","IPY_MODEL_29f69122b88042d1b88bef9c8a0e2ae1","IPY_MODEL_39149bef0b354567acd6b112a969ec59"],"layout":"IPY_MODEL_a879a0cfd80c4ca8bf3725d1f67e5a7f"}},"b74cb9d12ca24301a0dd90e2e78b3046":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdc6373a68f346b0aaf0259ac11a6a1f","placeholder":"​","style":"IPY_MODEL_3e73e189ba19479ca43c817b89acc950","value":"config.json: 100%"}},"29f69122b88042d1b88bef9c8a0e2ae1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7eba654b3e5447eead64b73c356f29d7","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4580cf3222604aa4bf3b2176bfc4bc17","value":570}},"39149bef0b354567acd6b112a969ec59":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_999a7a11ec0f4efb8d5a2387a0df7acf","placeholder":"​","style":"IPY_MODEL_01c82e6413cc41cfbcecb1051de6bc24","value":" 570/570 [00:00&lt;00:00, 56.6kB/s]"}},"a879a0cfd80c4ca8bf3725d1f67e5a7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdc6373a68f346b0aaf0259ac11a6a1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e73e189ba19479ca43c817b89acc950":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7eba654b3e5447eead64b73c356f29d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4580cf3222604aa4bf3b2176bfc4bc17":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"999a7a11ec0f4efb8d5a2387a0df7acf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01c82e6413cc41cfbcecb1051de6bc24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1ed41c926d84fc1bc88c2fa4c2f1311":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_187c327821584aea9c854839f7e3e569","IPY_MODEL_855fcca881de4f41abb05c316a8d2835","IPY_MODEL_b7bcc9c1d4a847ccbd6a55b5dcc5fc1e"],"layout":"IPY_MODEL_525b484a118643b8ab0be661d0ea9a58"}},"187c327821584aea9c854839f7e3e569":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85167696f0c342c49cff8c1160837271","placeholder":"​","style":"IPY_MODEL_ab9bf9136fc74f5f89341d6ba7d36f0e","value":"vocab.txt: 100%"}},"855fcca881de4f41abb05c316a8d2835":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a152f5a0e84841e9ba27065d4f8a002e","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_83f598c8e8f04fef88b11bffa5b71777","value":213450}},"b7bcc9c1d4a847ccbd6a55b5dcc5fc1e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93076cb254a04d27bf0d95408932d212","placeholder":"​","style":"IPY_MODEL_9f2b3eebb79740199a84c31aa3af834b","value":" 213k/213k [00:00&lt;00:00, 5.25MB/s]"}},"525b484a118643b8ab0be661d0ea9a58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85167696f0c342c49cff8c1160837271":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab9bf9136fc74f5f89341d6ba7d36f0e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a152f5a0e84841e9ba27065d4f8a002e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83f598c8e8f04fef88b11bffa5b71777":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"93076cb254a04d27bf0d95408932d212":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f2b3eebb79740199a84c31aa3af834b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5aa13dd2d89a4b33a496a900fcb80a13":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_87ef38f2d6bf4aefbc289f11da574fd7","IPY_MODEL_04401a97ac6a442398e4e321a4ee51aa","IPY_MODEL_fdd3468b02424204856dd8bae013fedc"],"layout":"IPY_MODEL_6fe6031e1d434ac5af150cbee1ba06df"}},"87ef38f2d6bf4aefbc289f11da574fd7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_801cdb9caf6e41958b55593331cfcba5","placeholder":"​","style":"IPY_MODEL_e2962c3f72584e18aa56c2ac74da4728","value":"tokenizer.json: 100%"}},"04401a97ac6a442398e4e321a4ee51aa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3286763181354e689251d1c335b8e861","max":435797,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6c8460b230e24b52b085d6ad6e9205cf","value":435797}},"fdd3468b02424204856dd8bae013fedc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6cd3f0d116f44188106b0486d334266","placeholder":"​","style":"IPY_MODEL_d4ec69e8da494ba0a2619a7c6cd4b7de","value":" 436k/436k [00:00&lt;00:00, 17.5MB/s]"}},"6fe6031e1d434ac5af150cbee1ba06df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"801cdb9caf6e41958b55593331cfcba5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2962c3f72584e18aa56c2ac74da4728":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3286763181354e689251d1c335b8e861":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c8460b230e24b52b085d6ad6e9205cf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b6cd3f0d116f44188106b0486d334266":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4ec69e8da494ba0a2619a7c6cd4b7de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a111d18931a4f069f363928f53d467b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_06903ebd44844c2a9aa3ec61c155d9da","IPY_MODEL_2063971605d54811ab616f7f09ee4c52","IPY_MODEL_0fd01f62fe53461dafa0a3d5ac04f275"],"layout":"IPY_MODEL_20a421f2869c47c8a76d1ade7e883a91"}},"06903ebd44844c2a9aa3ec61c155d9da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_521ef503342a4075accbcb4e5b5c3165","placeholder":"​","style":"IPY_MODEL_6b6338805f994c86a64297471c0d69fe","value":"config.json: 100%"}},"2063971605d54811ab616f7f09ee4c52":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff01a368832b417ab6f30b31d22a2c75","max":983,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c33adb58eeb944018803a0223957681a","value":983}},"0fd01f62fe53461dafa0a3d5ac04f275":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34d44ccf64654bde98fb8611868cc6ee","placeholder":"​","style":"IPY_MODEL_cd28712f0ff14bc49023b976c01f8e61","value":" 983/983 [00:00&lt;00:00, 99.3kB/s]"}},"20a421f2869c47c8a76d1ade7e883a91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"521ef503342a4075accbcb4e5b5c3165":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b6338805f994c86a64297471c0d69fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff01a368832b417ab6f30b31d22a2c75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c33adb58eeb944018803a0223957681a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"34d44ccf64654bde98fb8611868cc6ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd28712f0ff14bc49023b976c01f8e61":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ecf2ca697294e1fa07d8d08fab36b64":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_13a484d3f6f1447bbc78495480665d36","IPY_MODEL_a93e7affa86c4bde8a24f1df55668bab","IPY_MODEL_e5768460ef204b5eb474617dd219846c"],"layout":"IPY_MODEL_251316a251bf4b1687f3e8b1d7f9229a"}},"13a484d3f6f1447bbc78495480665d36":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0328720657804805976f66a7f3cd4420","placeholder":"​","style":"IPY_MODEL_a7420cf3b972433cb51aa8389c23bc87","value":"pytorch_model.bin: 100%"}},"a93e7affa86c4bde8a24f1df55668bab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d957d5720d8a4901962f199ceb31a990","max":430976911,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3e090726a19744bfbe2d152a072fc0fa","value":430976911}},"e5768460ef204b5eb474617dd219846c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0a2b256cb5344388e0f8bd2bad5392b","placeholder":"​","style":"IPY_MODEL_6c6f24e03257444e959a7e4c11db4616","value":" 431M/431M [00:04&lt;00:00, 136MB/s]"}},"251316a251bf4b1687f3e8b1d7f9229a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0328720657804805976f66a7f3cd4420":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7420cf3b972433cb51aa8389c23bc87":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d957d5720d8a4901962f199ceb31a990":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e090726a19744bfbe2d152a072fc0fa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a0a2b256cb5344388e0f8bd2bad5392b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c6f24e03257444e959a7e4c11db4616":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9df226eceba40d0aacefe835af3d099":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5672f34d42fe4176ac13aaa9dcdfddf7","IPY_MODEL_13383afc708b4ff5bbad4494dabcc66f","IPY_MODEL_1e0f5fd895034089b4a56f66d482ae11"],"layout":"IPY_MODEL_ee3ae39998c64beb847d70f8736d808e"}},"5672f34d42fe4176ac13aaa9dcdfddf7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84b2ec9134c04a30a8d26aea9ea77e2f","placeholder":"​","style":"IPY_MODEL_d89f88f9bbf44e87b355fc9f00e6403d","value":"model.safetensors: 100%"}},"13383afc708b4ff5bbad4494dabcc66f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_554b2c50f3b64fb8894d0a6913925cd0","max":430930848,"min":0,"orientation":"horizontal","style":"IPY_MODEL_624eed160b8a43669602a3e3efaa8130","value":430930848}},"1e0f5fd895034089b4a56f66d482ae11":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d4e721174c3437d96286a902e0f6bb2","placeholder":"​","style":"IPY_MODEL_0bfe33657ead4d08a91a790f4442a289","value":" 431M/431M [00:02&lt;00:00, 163MB/s]"}},"ee3ae39998c64beb847d70f8736d808e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84b2ec9134c04a30a8d26aea9ea77e2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d89f88f9bbf44e87b355fc9f00e6403d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"554b2c50f3b64fb8894d0a6913925cd0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"624eed160b8a43669602a3e3efaa8130":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7d4e721174c3437d96286a902e0f6bb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bfe33657ead4d08a91a790f4442a289":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"27c0524723164152863a33ad29a11c83":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1a634306035b44c799e22b46e6c35cbb","IPY_MODEL_e831bf324de84048baea27b7e5840e88","IPY_MODEL_d7d2f4cc7cd249719aa8547737a6c0f7"],"layout":"IPY_MODEL_18d3335736a7403386f7bed85e73e804"}},"1a634306035b44c799e22b46e6c35cbb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4db9b502ca1a43d0b77953b567da43ea","placeholder":"​","style":"IPY_MODEL_cdd24c397747473193f48d3f749230af","value":"Downloading builder script: 100%"}},"e831bf324de84048baea27b7e5840e88":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7bd2ab6525a4908ab68087bc8b61a95","max":6338,"min":0,"orientation":"horizontal","style":"IPY_MODEL_429fd8e4df38489896ea60332aa27b84","value":6338}},"d7d2f4cc7cd249719aa8547737a6c0f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccb9d8150a3a4e6a86fceb19940f5d1b","placeholder":"​","style":"IPY_MODEL_7b87a9800fe84cabaf3a652a1c7d1832","value":" 6.34k/6.34k [00:00&lt;00:00, 409kB/s]"}},"18d3335736a7403386f7bed85e73e804":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4db9b502ca1a43d0b77953b567da43ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdd24c397747473193f48d3f749230af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7bd2ab6525a4908ab68087bc8b61a95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"429fd8e4df38489896ea60332aa27b84":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ccb9d8150a3a4e6a86fceb19940f5d1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b87a9800fe84cabaf3a652a1c7d1832":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}